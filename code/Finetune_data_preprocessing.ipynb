{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abaciscus',\n",
       " 'perioral',\n",
       " 'aerialness',\n",
       " 'sphenotripsy',\n",
       " 'grafter',\n",
       " 'hatti',\n",
       " 'pneumoventriculography',\n",
       " 'reavoid',\n",
       " 'bookstall',\n",
       " 'samal',\n",
       " 'rebenediction',\n",
       " 'restrictively',\n",
       " 'unminuted',\n",
       " 'granary',\n",
       " 'geography',\n",
       " 'velatura',\n",
       " 'electrogilt',\n",
       " 'viand',\n",
       " 'headset',\n",
       " 'destour',\n",
       " 'musculoarterial',\n",
       " 'kaisership',\n",
       " 'spongiosity',\n",
       " 'doorboy',\n",
       " 'helvetian',\n",
       " 'uncondensing',\n",
       " 'stuiver',\n",
       " 'tonkawa',\n",
       " 'outcropper',\n",
       " 'vat',\n",
       " 'replod',\n",
       " 'pawkily',\n",
       " 'rhabdomancer',\n",
       " 'unindividual',\n",
       " 'tungstenic',\n",
       " 'neugroschen',\n",
       " 'kuomintang',\n",
       " 'melitemia',\n",
       " 'postaxial',\n",
       " 'getup',\n",
       " 'scissortail',\n",
       " 'dysorexy',\n",
       " 'paraphrenitis',\n",
       " 'solferino',\n",
       " 'crokinole',\n",
       " 'acredula',\n",
       " 'unbuffed',\n",
       " 'seminific',\n",
       " 'multiramified',\n",
       " 'neffy',\n",
       " 'topcoating',\n",
       " 'anythingarian',\n",
       " 'asbestos',\n",
       " 'alkahest',\n",
       " 'crematorial',\n",
       " 'unquarried',\n",
       " 'oppugn',\n",
       " 'lycaena',\n",
       " 'tussal',\n",
       " 'hartleyan',\n",
       " 'lemuel',\n",
       " 'porcellanize',\n",
       " 'censer',\n",
       " 'polemician',\n",
       " 'neutralization',\n",
       " 'breathingly',\n",
       " 'artifice',\n",
       " 'abrocome',\n",
       " 'drusean',\n",
       " 'intervallic',\n",
       " 'paratroop',\n",
       " 'recountable',\n",
       " 'whitterick',\n",
       " 'isobarbaloin',\n",
       " 'leath',\n",
       " 'singled',\n",
       " 'spoonbill',\n",
       " 'genial',\n",
       " 'tribual',\n",
       " 'digamist',\n",
       " 'roadwise',\n",
       " 'crumpling',\n",
       " 'discography',\n",
       " 'unsampled',\n",
       " 'metaloscopy',\n",
       " 'gradine',\n",
       " 'sabra',\n",
       " 'nondisciplinary',\n",
       " 'cacosmia',\n",
       " 'sergiu',\n",
       " 'unpreferable',\n",
       " 'nulliparity',\n",
       " 'aperistalsis',\n",
       " 'alibi',\n",
       " 'girasol',\n",
       " 'headrope',\n",
       " 'shoad',\n",
       " 'unitarianism',\n",
       " 'ravishing',\n",
       " 'sepulcher',\n",
       " 'milleporiform',\n",
       " 'multifactorial',\n",
       " 'anomite',\n",
       " 'lipoprotein',\n",
       " 'postembryonic',\n",
       " 'yabber',\n",
       " 'finalism',\n",
       " 'epistomian',\n",
       " 'gym',\n",
       " 'britannically',\n",
       " 'existence',\n",
       " 'miscanonize',\n",
       " 'neocyanine',\n",
       " 'realizable',\n",
       " 'unforgettably',\n",
       " 'antiphonally',\n",
       " 'whitewing',\n",
       " 'priscilla',\n",
       " 'ungelatinized',\n",
       " 'abanic',\n",
       " 'triunal',\n",
       " 'satiate',\n",
       " 'broll',\n",
       " 'plowjogger',\n",
       " 'wifish',\n",
       " 'operculigerous',\n",
       " 'ophthalmolith',\n",
       " 'matrimoniously',\n",
       " 'posthypophysis',\n",
       " 'talinum',\n",
       " 'velvetweed',\n",
       " 'aristotype',\n",
       " 'straik',\n",
       " 'undisrupted',\n",
       " 'vulcanization',\n",
       " 'colloquia',\n",
       " 'jerkiness',\n",
       " 'aimee',\n",
       " 'farmeress',\n",
       " 'fascicule',\n",
       " 'unridiculous',\n",
       " 'petrographically',\n",
       " 'rebrick',\n",
       " 'loamy',\n",
       " 'desmopexia',\n",
       " 'myricaceae',\n",
       " 'ultimogenitary',\n",
       " 'oversimplify',\n",
       " 'illano',\n",
       " 'journal',\n",
       " 'sinuously',\n",
       " 'obsignation',\n",
       " 'exorcism',\n",
       " 'counterpreparation',\n",
       " 'oologic',\n",
       " 'unvolatile',\n",
       " 'dermochrome',\n",
       " 'rokee',\n",
       " 'vuln',\n",
       " 'poorweed',\n",
       " 'antituberculotic',\n",
       " 'poisonful',\n",
       " 'ultramodern',\n",
       " 'mythometer',\n",
       " 'patientless',\n",
       " 'unhelped',\n",
       " 'longipennine',\n",
       " 'anile',\n",
       " 'inobedient',\n",
       " 'pesterous',\n",
       " 'hypoconule',\n",
       " 'actionable',\n",
       " 'dimensible',\n",
       " 'unprospered',\n",
       " 'vallum',\n",
       " 'subaduncate',\n",
       " 'calcareoargillaceous',\n",
       " 'chalmer',\n",
       " 'rhegmatype',\n",
       " 'confute',\n",
       " 'flamberg',\n",
       " 'rascally',\n",
       " 'massedness',\n",
       " 'gasterosteidae',\n",
       " 'onomantia',\n",
       " 'kompeni',\n",
       " 'slovakian',\n",
       " 'miswrite',\n",
       " 'indescribability',\n",
       " 'jayhawker',\n",
       " 'maxillary',\n",
       " 'hydraulics',\n",
       " 'hyperoxygenize',\n",
       " 'inanely',\n",
       " 'hibernicize',\n",
       " 'peritrema',\n",
       " 'roundseam',\n",
       " 'blush',\n",
       " 'sozolic',\n",
       " 'extubate',\n",
       " 'reachieve',\n",
       " 'outhousing',\n",
       " 'even',\n",
       " 'myometrium',\n",
       " 'semeiotical',\n",
       " 'unacknowledged',\n",
       " 'orchidoptosis',\n",
       " 'webwork',\n",
       " 'overlearnedness',\n",
       " 'homoeomorphy',\n",
       " 'ultramicrometer',\n",
       " 'filialness',\n",
       " 'rancid',\n",
       " 'ashipboard',\n",
       " 'phalerated',\n",
       " 'boree',\n",
       " 'endothecial',\n",
       " 'cherubim',\n",
       " 'uncoffined',\n",
       " 'entrepot',\n",
       " 'plowrightia',\n",
       " 'popify',\n",
       " 'barreler',\n",
       " 'personalistic',\n",
       " 'stealing',\n",
       " 'vaginovesical',\n",
       " 'glottic',\n",
       " 'appetibleness',\n",
       " 'pinheadedness',\n",
       " 'shrewdly',\n",
       " 'birefraction',\n",
       " 'eluvium',\n",
       " 'isogonality',\n",
       " 'ventrodorsal',\n",
       " 'obstructant',\n",
       " 'frigostable',\n",
       " 'plethoric',\n",
       " 'strabismal',\n",
       " 'providentness',\n",
       " 'pyrotritartric',\n",
       " 'araroba',\n",
       " 'perifolliculitis',\n",
       " 'unapocryphal',\n",
       " 'almsgiving',\n",
       " 'nonfinding',\n",
       " 'derater',\n",
       " 'amphineura',\n",
       " 'nonretractation',\n",
       " 'sternoclidomastoid',\n",
       " 'tandemwise',\n",
       " 'slander',\n",
       " 'orational',\n",
       " 'jibstay',\n",
       " 'stichically',\n",
       " 'anticonscriptive',\n",
       " 'ratcher',\n",
       " 'impregnability',\n",
       " 'ventifact',\n",
       " 'vixenishly',\n",
       " 'pabulous',\n",
       " 'actinopteran',\n",
       " 'multibranched',\n",
       " 'maltase',\n",
       " 'suboxidation',\n",
       " 'cocainomaniac',\n",
       " 'waterboard',\n",
       " 'sarkit',\n",
       " 'cafenet',\n",
       " 'conceitless',\n",
       " 'hydroponics',\n",
       " 'bathmic',\n",
       " 'foldedly',\n",
       " 'jateorhiza',\n",
       " 'parrotism',\n",
       " 'skedaddler',\n",
       " 'autolatry',\n",
       " 'unmummify',\n",
       " 'strophotaxis',\n",
       " 'respirit',\n",
       " 'crutching',\n",
       " 'medregal',\n",
       " 'villanage',\n",
       " 'sphenoid',\n",
       " 'poesiless',\n",
       " 'feal',\n",
       " 'isuridae',\n",
       " 'flyingly',\n",
       " 'misjoinder',\n",
       " 'overpitched',\n",
       " 'nusairis',\n",
       " 'allomerous',\n",
       " 'throstle',\n",
       " 'boondock',\n",
       " 'feudatorial',\n",
       " 'dromiceius',\n",
       " 'endways',\n",
       " 'sherbet',\n",
       " 'periscopal',\n",
       " 'kumiss',\n",
       " 'uniserrate',\n",
       " 'mensural',\n",
       " 'unlovelily',\n",
       " 'polyploidic',\n",
       " 'apteral',\n",
       " 'clanswoman',\n",
       " 'disciplinability',\n",
       " 'ceratophyta',\n",
       " 'disappointed',\n",
       " 'taur',\n",
       " 'bedouin',\n",
       " 'illuminate',\n",
       " 'germanely',\n",
       " 'ceramographic',\n",
       " 'interstitious',\n",
       " 'levant',\n",
       " 'alchemically',\n",
       " 'rochelime',\n",
       " 'allicholly',\n",
       " 'scope',\n",
       " 'aphorismatic',\n",
       " 'anospinal',\n",
       " 'duplone',\n",
       " 'oxtail',\n",
       " 'cataplasia',\n",
       " 'conima',\n",
       " 'polystyrene',\n",
       " 'rebait',\n",
       " 'brachyprosopic',\n",
       " 'iatric',\n",
       " 'anticrisis',\n",
       " 'cardo',\n",
       " 'inconsistentness',\n",
       " 'tailge',\n",
       " 'unserried',\n",
       " 'fitted',\n",
       " 'jurator',\n",
       " 'lichenaceous',\n",
       " 'unimedial',\n",
       " 'shovelfish',\n",
       " 'flagroot',\n",
       " 'undertest',\n",
       " 'violatory',\n",
       " 'noncohesion',\n",
       " 'asta',\n",
       " 'subsistency',\n",
       " 'proirrigation',\n",
       " 'nonaccomplishment',\n",
       " 'biddulphia',\n",
       " 'overgoad',\n",
       " 'headrace',\n",
       " 'pericardotomy',\n",
       " 'subgenus',\n",
       " 'mismeasurement',\n",
       " 'aneurin',\n",
       " 'buckra',\n",
       " 'calycle',\n",
       " 'pentaglossal',\n",
       " 'busky',\n",
       " 'horsiness',\n",
       " 'superdose',\n",
       " 'marrella',\n",
       " 'precommissural',\n",
       " 'semideveloped',\n",
       " 'reseam',\n",
       " 'sunweed',\n",
       " 'unicorn',\n",
       " 'counterposting',\n",
       " 'leafboy',\n",
       " 'superexceeding',\n",
       " 'nontabular',\n",
       " 'buggyman',\n",
       " 'thesial',\n",
       " 'frontignan',\n",
       " 'suboverseer',\n",
       " 'altercative',\n",
       " 'shamefaced',\n",
       " 'eucharistial',\n",
       " 'ionizer',\n",
       " 'lachrymosely',\n",
       " 'everylike',\n",
       " 'diazobenzene',\n",
       " 'mesosigmoid',\n",
       " 'supervive',\n",
       " 'zoomelanin',\n",
       " 'tragedienne',\n",
       " 'bocasine',\n",
       " 'interspinous',\n",
       " 'exodus',\n",
       " 'negative',\n",
       " 'orthotactic',\n",
       " 'microzone',\n",
       " 'episcopable',\n",
       " 'cheekiness',\n",
       " 'rype',\n",
       " 'siliceous',\n",
       " 'caissoned',\n",
       " 'benightment',\n",
       " 'superelegance',\n",
       " 'solepiece',\n",
       " 'chanfrin',\n",
       " 'feaberry',\n",
       " 'demoded',\n",
       " 'megalodactylous',\n",
       " 'compatibleness',\n",
       " 'malm',\n",
       " 'underaction',\n",
       " 'harmonically',\n",
       " 'browache',\n",
       " 'gaby',\n",
       " 'heterauxesis',\n",
       " 'mixedly',\n",
       " 'ovatoconical',\n",
       " 'encumberingly',\n",
       " 'perineocele',\n",
       " 'atheist',\n",
       " 'quadratic',\n",
       " 'restretch',\n",
       " 'unjarring',\n",
       " 'telfairia',\n",
       " 'weirdish',\n",
       " 'potamogeton',\n",
       " 'venturine',\n",
       " 'braille',\n",
       " 'concenter',\n",
       " 'subapprobation',\n",
       " 'bisglyoxaline',\n",
       " 'prefiguratively',\n",
       " 'pseudotabes',\n",
       " 'unfactional',\n",
       " 'pecuniosity',\n",
       " 'eyeletter',\n",
       " 'bossism',\n",
       " 'sullenly',\n",
       " 'endorse',\n",
       " 'helicline',\n",
       " 'bibliolatry',\n",
       " 'receiptless',\n",
       " 'fistmele',\n",
       " 'photosensitization',\n",
       " 'sufficingness',\n",
       " 'sherrymoor',\n",
       " 'weelfaured',\n",
       " 'octagonally',\n",
       " 'demicuirass',\n",
       " 'directiveness',\n",
       " 'nitride',\n",
       " 'mercerizer',\n",
       " 'aphasic',\n",
       " 'nonfreedom',\n",
       " 'bloodwood',\n",
       " 'coloptosis',\n",
       " 'unrooting',\n",
       " 'irrecognizable',\n",
       " 'overdogmatism',\n",
       " 'ornateness',\n",
       " 'indocility',\n",
       " 'unaccreditated',\n",
       " 'cisterna',\n",
       " 'mousebane',\n",
       " 'insnare',\n",
       " 'torrentine',\n",
       " 'overgang',\n",
       " 'jaspilite',\n",
       " 'copperwing',\n",
       " 'tcherkess',\n",
       " 'webmaker',\n",
       " 'anecdotist',\n",
       " 'semiarborescent',\n",
       " 'cerous',\n",
       " 'desonation',\n",
       " 'jinniwink',\n",
       " 'nonmaterialistic',\n",
       " 'unadulterous',\n",
       " 'uncoly',\n",
       " 'unintensive',\n",
       " 'witchweed',\n",
       " 'hectorism',\n",
       " 'anarchically',\n",
       " 'heteroptics',\n",
       " 'inrunning',\n",
       " 'magazinist',\n",
       " 'uniaxally',\n",
       " 'proelectrification',\n",
       " 'phyletically',\n",
       " 'heartsomely',\n",
       " 'untasty',\n",
       " 'negotiatory',\n",
       " 'chappaul',\n",
       " 'tatsman',\n",
       " 'dispersonify',\n",
       " 'cocanucos',\n",
       " 'gastrojejunal',\n",
       " 'blisterweed',\n",
       " 'mahseer',\n",
       " 'periependymal',\n",
       " 'laughable',\n",
       " 'infinituple',\n",
       " 'infernality',\n",
       " 'acclinate',\n",
       " 'ovovivipara',\n",
       " 'slavonism',\n",
       " 'tractably',\n",
       " 'mensurableness',\n",
       " 'poleless',\n",
       " 'sinupallialia',\n",
       " 'respectlessly',\n",
       " 'callet',\n",
       " 'scleromere',\n",
       " 'squamelliferous',\n",
       " 'dratting',\n",
       " 'gaucho',\n",
       " 'undershorten',\n",
       " 'drawboard',\n",
       " 'mulefoot',\n",
       " 'preponderant',\n",
       " 'intercortical',\n",
       " 'thaumaturgia',\n",
       " 'theomania',\n",
       " 'splenocyte',\n",
       " 'hilus',\n",
       " 'mirrorscope',\n",
       " 'cholecystalgia',\n",
       " 'asphyxia',\n",
       " 'dresser',\n",
       " 'mannequin',\n",
       " 'engineman',\n",
       " 'rhodymeniaceous',\n",
       " 'rhynchophora',\n",
       " 'streptobacillus',\n",
       " 'cowardliness',\n",
       " 'zonite',\n",
       " 'tranquilization',\n",
       " 'manifoldly',\n",
       " 'misresult',\n",
       " 'metatype',\n",
       " 'thankworthy',\n",
       " 'blasthole',\n",
       " 'stigmatal',\n",
       " 'semiramis',\n",
       " 'handgrip',\n",
       " 'almug',\n",
       " 'lymphocytosis',\n",
       " 'amantillo',\n",
       " 'chiller',\n",
       " 'detailedness',\n",
       " 'atrorubent',\n",
       " 'conflagration',\n",
       " 'majorist',\n",
       " 'rehumble',\n",
       " 'moluche',\n",
       " 'incircumspectness',\n",
       " 'hypothenar',\n",
       " 'isosporic',\n",
       " 'inlayer',\n",
       " 'coempt',\n",
       " 'nonidealist',\n",
       " 'incontemptible',\n",
       " 'sprottle',\n",
       " 'madrier',\n",
       " 'porger',\n",
       " 'reversewise',\n",
       " 'interacinar',\n",
       " 'posting',\n",
       " 'carpetwoven',\n",
       " 'stillion',\n",
       " 'bedeafen',\n",
       " 'revenuer',\n",
       " 'hydrobomb',\n",
       " 'infusionist',\n",
       " 'insufflator',\n",
       " 'melano',\n",
       " 'lectureship',\n",
       " 'heminee',\n",
       " 'marsupiata',\n",
       " 'veronal',\n",
       " 'malesherbia',\n",
       " 'subservientness',\n",
       " 'bourbonize',\n",
       " 'ingravidate',\n",
       " 'cephalocereus',\n",
       " 'smoothback',\n",
       " 'charkha',\n",
       " 'widework',\n",
       " 'adulterously',\n",
       " 'benzanthrone',\n",
       " 'rutherfordine',\n",
       " 'animality',\n",
       " 'sarcoderm',\n",
       " 'kanoon',\n",
       " 'zeunerite',\n",
       " 'carnassial',\n",
       " 'discursiveness',\n",
       " 'undertakingly',\n",
       " 'sympathicotripsy',\n",
       " 'hyracothere',\n",
       " 'watershoot',\n",
       " 'persuadable',\n",
       " 'stultiloquence',\n",
       " 'inclement',\n",
       " 'erotetic',\n",
       " 'stubbornhearted',\n",
       " 'labyrinthally',\n",
       " 'otosalpinx',\n",
       " 'carabao',\n",
       " 'ischiorrhogic',\n",
       " 'scandian',\n",
       " 'araby',\n",
       " 'unlettable',\n",
       " 'zygomaticum',\n",
       " 'infinitude',\n",
       " 'cryptogamia',\n",
       " 'lux',\n",
       " 'oligochrome',\n",
       " 'photolyte',\n",
       " 'munificently',\n",
       " 'mudhead',\n",
       " 'outbirth',\n",
       " 'dedan',\n",
       " 'epergne',\n",
       " 'mossi',\n",
       " 'rubywise',\n",
       " 'quackster',\n",
       " 'elpasolite',\n",
       " 'nonaqueous',\n",
       " 'mealproof',\n",
       " 'pneumonolith',\n",
       " 'teletranscription',\n",
       " 'shiftful',\n",
       " 'bequeathment',\n",
       " 'sokulk',\n",
       " 'glires',\n",
       " 'elucubration',\n",
       " 'procuratrix',\n",
       " 'proelectric',\n",
       " 'paragraphism',\n",
       " 'teemful',\n",
       " 'olof',\n",
       " 'clavicylinder',\n",
       " 'underwalk',\n",
       " 'manometric',\n",
       " 'unedibly',\n",
       " 'aeromechanics',\n",
       " 'monorchid',\n",
       " 'phosis',\n",
       " 'edwardian',\n",
       " 'papulate',\n",
       " 'barrowist',\n",
       " 'polyspored',\n",
       " 'binder',\n",
       " 'intertergal',\n",
       " 'electroetching',\n",
       " 'phalloplasty',\n",
       " 'krantzite',\n",
       " 'unconveniently',\n",
       " 'perlection',\n",
       " 'splore',\n",
       " 'committeeship',\n",
       " 'unparted',\n",
       " 'lighting',\n",
       " 'apomecometer',\n",
       " 'arkansawyer',\n",
       " 'intertubular',\n",
       " 'luxation',\n",
       " 'zoobenthos',\n",
       " 'serendite',\n",
       " 'unconspicuously',\n",
       " 'tridominium',\n",
       " 'bungy',\n",
       " 'hematocyanin',\n",
       " 'tukuler',\n",
       " 'merk',\n",
       " 'coif',\n",
       " 'undeclinable',\n",
       " 'uneasiness',\n",
       " 'sodalist',\n",
       " 'nonjurant',\n",
       " 'lassieish',\n",
       " 'bedsore',\n",
       " 'multungulate',\n",
       " 'nonmetropolitan',\n",
       " 'unsincere',\n",
       " 'flux',\n",
       " 'attributable',\n",
       " 'blackbirding',\n",
       " 'volitional',\n",
       " 'hepatostomy',\n",
       " 'hemikaryotic',\n",
       " 'calcipexy',\n",
       " 'pintadera',\n",
       " 'vergerism',\n",
       " 'umbracious',\n",
       " 'uncoronated',\n",
       " 'obtuse',\n",
       " 'porcula',\n",
       " 'undismayed',\n",
       " 'ornithocephalus',\n",
       " 'localizable',\n",
       " 'exodist',\n",
       " 'brabblement',\n",
       " 'cucujid',\n",
       " 'enarch',\n",
       " 'dafla',\n",
       " 'paintress',\n",
       " 'granulite',\n",
       " 'anosia',\n",
       " 'intenable',\n",
       " 'eductor',\n",
       " 'disordained',\n",
       " 'funder',\n",
       " 'forfeiture',\n",
       " 'antiquity',\n",
       " 'desmodontidae',\n",
       " 'juggling',\n",
       " 'hypsophonous',\n",
       " 'elod',\n",
       " 'belshazzar',\n",
       " 'gastroparietal',\n",
       " 'incongenial',\n",
       " 'isogenic',\n",
       " 'bunk',\n",
       " 'procensorship',\n",
       " 'megaloenteron',\n",
       " 'chanter',\n",
       " 'abbasi',\n",
       " 'paratrooper',\n",
       " 'stonish',\n",
       " 'fogfruit',\n",
       " 'tangibile',\n",
       " 'sutleress',\n",
       " 'liturgistic',\n",
       " 'emperorship',\n",
       " 'triplication',\n",
       " 'oxlike',\n",
       " 'populationless',\n",
       " 'bovinely',\n",
       " 'inscriptured',\n",
       " 'jimpricute',\n",
       " 'ribston',\n",
       " 'menstruum',\n",
       " 'cerebropsychosis',\n",
       " 'arbitrable',\n",
       " 'hariolation',\n",
       " 'creativeness',\n",
       " 'septoic',\n",
       " 'disruptable',\n",
       " 'invar',\n",
       " 'helladian',\n",
       " 'metaphenomenon',\n",
       " 'deity',\n",
       " 'perinephric',\n",
       " 'autoparasitism',\n",
       " 'sovereign',\n",
       " 'unpossibility',\n",
       " 'avowant',\n",
       " 'antimeristem',\n",
       " 'kainyn',\n",
       " 'commorancy',\n",
       " 'azerbaijanese',\n",
       " 'polyschematic',\n",
       " 'toxifer',\n",
       " 'apotracheal',\n",
       " 'unscaly',\n",
       " 'reinclination',\n",
       " 'fibropapilloma',\n",
       " 'hyperconscientiousness',\n",
       " 'cathion',\n",
       " 'ciceronianism',\n",
       " 'tutball',\n",
       " 'downweigh',\n",
       " 'atropidae',\n",
       " 'yellowishness',\n",
       " 'tawgi',\n",
       " 'unadulterately',\n",
       " 'linitis',\n",
       " 'antigambling',\n",
       " 'lithomancy',\n",
       " 'unpocketed',\n",
       " 'chehalis',\n",
       " 'goff',\n",
       " 'prediscussion',\n",
       " 'ripcord',\n",
       " 'underdown',\n",
       " 'peritonitic',\n",
       " 'unmendableness',\n",
       " 'asellate',\n",
       " 'antennulary',\n",
       " 'hula',\n",
       " 'satrapal',\n",
       " 'bolsterer',\n",
       " 'paramilitary',\n",
       " 'underplate',\n",
       " 'inclemently',\n",
       " 'orphanship',\n",
       " 'cartist',\n",
       " 'nate',\n",
       " 'amphitoky',\n",
       " 'nonextradition',\n",
       " 'resumption',\n",
       " 'stressless',\n",
       " 'voltammeter',\n",
       " 'exceptant',\n",
       " 'moisture',\n",
       " 'ineligible',\n",
       " 'summeriness',\n",
       " 'spingel',\n",
       " 'unembarrassing',\n",
       " 'stefan',\n",
       " 'reprobater',\n",
       " 'interminable',\n",
       " 'nonequal',\n",
       " 'front',\n",
       " 'pallette',\n",
       " 'swird',\n",
       " 'stammer',\n",
       " 'parthenopaeus',\n",
       " 'progressiveness',\n",
       " 'surfle',\n",
       " 'flunk',\n",
       " 'tetrazolium',\n",
       " 'jato',\n",
       " 'turritellid',\n",
       " 'dilutor',\n",
       " 'briolette',\n",
       " 'gyromancy',\n",
       " 'geoplana',\n",
       " 'moph',\n",
       " 'bagged',\n",
       " 'homogenetic',\n",
       " 'paradoxides',\n",
       " 'staggarth',\n",
       " 'gloryful',\n",
       " 'gesten',\n",
       " 'lantaca',\n",
       " 'incapably',\n",
       " 'staio',\n",
       " 'antigone',\n",
       " 'balangay',\n",
       " 'neostyle',\n",
       " 'tri',\n",
       " 'malleable',\n",
       " 'xanthione',\n",
       " 'misperform',\n",
       " 'moleism',\n",
       " 'prolongate',\n",
       " 'cibarial',\n",
       " 'betonica',\n",
       " 'underbud',\n",
       " 'propyl',\n",
       " 'myosote',\n",
       " 'adad',\n",
       " 'charioted',\n",
       " 'delitescence',\n",
       " 'satyresque',\n",
       " 'stairless',\n",
       " 'octoechos',\n",
       " 'toyishness',\n",
       " 'unstate',\n",
       " 'reregistration',\n",
       " 'confutable',\n",
       " 'gaudery',\n",
       " 'edemic',\n",
       " 'cribo',\n",
       " 'epicauta',\n",
       " 'muddlebrained',\n",
       " 'decolorizer',\n",
       " 'galvanometrically',\n",
       " 'stepwise',\n",
       " 'incompressibly',\n",
       " 'crepusculine',\n",
       " 'supercarbonate',\n",
       " 'ultracondenser',\n",
       " 'volley',\n",
       " 'egypt',\n",
       " 'slabber',\n",
       " 'ossifrangent',\n",
       " 'pawnshop',\n",
       " 'thickskin',\n",
       " 'contorniate',\n",
       " 'granter',\n",
       " 'dictational',\n",
       " 'acutifoliate',\n",
       " 'siphuncular',\n",
       " 'biacetylene',\n",
       " 'begone',\n",
       " 'mastological',\n",
       " 'latecoming',\n",
       " 'lymphatitis',\n",
       " 'cosset',\n",
       " 'dynagraph',\n",
       " 'mustela',\n",
       " 'chapeau',\n",
       " 'acerbic',\n",
       " 'guayabi',\n",
       " 'unshipshape',\n",
       " 'dispeoplement',\n",
       " 'decrudescence',\n",
       " 'ispravnik',\n",
       " 'hemimelus',\n",
       " 'pyrologist',\n",
       " 'adipsous',\n",
       " 'contractile',\n",
       " 'coxarthrocace',\n",
       " 'dechemicalization',\n",
       " 'lophosteon',\n",
       " 'aleyrodidae',\n",
       " 'unsad',\n",
       " 'westermost',\n",
       " 'nonallegation',\n",
       " 'matching',\n",
       " 'estmark',\n",
       " 'euphuist',\n",
       " 'manganiferous',\n",
       " 'xiphisura',\n",
       " 'senatorship',\n",
       " 'slew',\n",
       " 'wickedness',\n",
       " 'neuromatosis',\n",
       " 'pentacetate',\n",
       " 'inamissibility',\n",
       " 'primrose',\n",
       " 'unfertile',\n",
       " 'discordantly',\n",
       " 'unimodular',\n",
       " 'preindependence',\n",
       " 'uninjected',\n",
       " 'unskilledly',\n",
       " 'ungamelike',\n",
       " 'protomonostelic',\n",
       " 'astipulate',\n",
       " 'everwho',\n",
       " 'deoppilant',\n",
       " 'colonizable',\n",
       " 'wilga',\n",
       " 'scripturient',\n",
       " 'affinely',\n",
       " 'floggable',\n",
       " 'questionable',\n",
       " 'osteofibroma',\n",
       " 'quesitive',\n",
       " 'nahua',\n",
       " 'represcribe',\n",
       " 'jirble',\n",
       " 'midforenoon',\n",
       " 'feltwork',\n",
       " 'holmium',\n",
       " 'shooi',\n",
       " 'fertilizer',\n",
       " 'conglobately',\n",
       " 'louise',\n",
       " 'neoplasmata',\n",
       " 'rotse',\n",
       " 'impermeabilize',\n",
       " 'tearful',\n",
       " 'planisher',\n",
       " 'tenuiroster',\n",
       " 'anthomedusan',\n",
       " 'catechization',\n",
       " 'hut',\n",
       " 'amarillo',\n",
       " 'yaw',\n",
       " 'phocid',\n",
       " 'threadfin',\n",
       " 'thrillproof',\n",
       " 'bordroom',\n",
       " 'hearthwarming',\n",
       " 'rifledom',\n",
       " 'circumvolutory',\n",
       " 'ketting',\n",
       " 'calcinatory',\n",
       " 'theoremic',\n",
       " 'volation',\n",
       " 'bibliothecarian',\n",
       " 'pickeringite',\n",
       " 'tethydan',\n",
       " 'syntomia',\n",
       " 'fretfulness',\n",
       " 'fowlfoot',\n",
       " 'lysimachus',\n",
       " 'shorthead',\n",
       " 'simal',\n",
       " 'pygobranchia',\n",
       " 'malouah',\n",
       " 'proairesis',\n",
       " 'pallholder',\n",
       " 'stenter',\n",
       " 'cryptogamy',\n",
       " 'alnaschar',\n",
       " 'unfelonious',\n",
       " 'protelytropteron',\n",
       " 'protodonatan',\n",
       " 'esopus',\n",
       " 'interbalance',\n",
       " 'anaxon',\n",
       " 'plicateness',\n",
       " 'plumbage',\n",
       " 'costumiere',\n",
       " 'niggardliness',\n",
       " 'pristipomatidae',\n",
       " 'befile',\n",
       " 'kelek',\n",
       " ...}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dictionary of English words\n",
    "\n",
    "import nltk\n",
    "# nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "dictwords = set(x.lower() for x in words.words())\n",
    "dictwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing contractions compiled by Ahmed\n",
    "\n",
    "# import pandas as pd\n",
    "# df = pd.read_excel('C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/Code/ahmed/contractions.xlsx')\n",
    "# contractions = df.set_index('contraction').to_dict()['meaning']\n",
    "\n",
    "contractions = {\n",
    " \"aren't\": 'are not',\n",
    " \"can't\": 'cannot',\n",
    " \"could've\": 'could have',\n",
    " \"couldn't\": 'could not',\n",
    " \"didn't\": 'did not',\n",
    " \"doesn't\": 'does not',\n",
    " \"don't\": 'do not',\n",
    " 'gonna': 'going to',\n",
    " 'gotta': 'got to',\n",
    " \"hadn't\": 'had not',\n",
    " \"hasn't\": 'has not',\n",
    " \"haven't\": 'have not',\n",
    " \"he'd\": 'he would',\n",
    " \"he'll\": 'he will',\n",
    " \"he's\": 'he is',\n",
    " \"how's\": 'how is',\n",
    " \"I'd\": 'I would',\n",
    " \"I'll\": 'I will',\n",
    " \"I'm\": 'I am',\n",
    " \"i'm\": 'I am',\n",
    " \"I've\": 'I have',\n",
    " \"isn't\": 'is not',\n",
    " \"it'd\": 'it would',\n",
    " \"it'll\": 'it will',\n",
    " \"it's\": 'it is',\n",
    " \"mayn't\": 'may not',\n",
    " \"may've\": 'may have',\n",
    " \"mightn't\": 'might not',\n",
    " \"might've\": 'might have',\n",
    " \"mustn't\": 'must not',\n",
    " \"must've\": 'must have',\n",
    " \"needn't\": 'need not',\n",
    " \"o'clock\": 'of the clock',\n",
    " \"oughtn't\": 'ought not',\n",
    " \"she'd\": 'she would',\n",
    " \"she'll\": 'she will',\n",
    " \"she's\": 'she is',\n",
    " \"should've\": 'should have',\n",
    " \"shouldn't\": 'should not',\n",
    " \"that's\": 'that is',\n",
    " \"there're\": 'there are',\n",
    " \"there's\": 'there is',\n",
    " \"these're\": 'these are',\n",
    " \"they'd\": 'they would',\n",
    " \"they'll\": 'they will',\n",
    " \"they're\": 'they are',\n",
    " \"they've\": 'they have',\n",
    " \"this's\": 'this is',\n",
    " \"those're\": 'those are',\n",
    " \"wasn't\": 'was not',\n",
    " \"we'd\": 'we would',\n",
    " \"we'll\": 'we will',\n",
    " \"we're\": 'we are',\n",
    " \"we've\": 'we have',\n",
    " \"weren't\": 'were not',\n",
    " \"what'll\": 'what will',\n",
    " \"what're\": 'what are',\n",
    " \"what's\": 'what is',\n",
    " \"what've\": 'what have',\n",
    " \"when's\": 'when is',\n",
    " \"where're\": 'where are',\n",
    " \"where's\": 'where is',\n",
    " \"which's\": 'which is',\n",
    " \"who'd\": 'who would',\n",
    " \"who'll\": 'who will',\n",
    " \"who're\": 'who are',\n",
    " \"who's\": 'who is',\n",
    " \"why's\": 'why is',\n",
    " \"won't\": 'will not',\n",
    " \"would've\": 'would have',\n",
    " \"wouldn't\": 'would not',\n",
    " \"you'd\": 'you would',\n",
    " \"you'll\": 'you will',\n",
    " \"you're\": 'you are',\n",
    " \"you've\": 'you have'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacement dictionary compiled by Ahmed\n",
    "\n",
    "replacement_dict = {\n",
    "    '\\n' : ' ',\n",
    "    '!=' : ' not equal ',\n",
    "    '=' : ' equal ',\n",
    "    b'\\xc2\\xae'.decode() : ' registered_sign ', # ®\n",
    "    '\\x92' : ' ',\n",
    "    '\\x91' : ' ',\n",
    "    '\\x96' : ' ',\n",
    "    b'\\xe2\\x84\\xa2'.decode() : ' trademark_sign ', # ™\n",
    "    b'\\xe2\\x80\\x90'.decode() : '-',\n",
    "    '}': ')',\n",
    "    '{': '(',\n",
    "    b'\\xc2\\xb2'.decode() : ' squared ',\n",
    "    b'\\xc2\\xa7'.decode() : ' section ',  # §\n",
    "    b'\\xc2\\xb0'.decode() : ' degrees ',\n",
    "    b'\\xe2\\x80\\xa6'.decode() : ' . ',   # …\n",
    "    '\\$' : ' dollar ',\n",
    "    b'\\xe2\\x82\\xac'.decode() : ' euro ',\n",
    "    '\\|' : ' , ',    \n",
    "    b'\\xc2\\xab'.decode() : ' \\\" ',\n",
    "    b'\\xc2\\xbb'.decode() : ' \\\" ',\n",
    "    '\\+' : ' plus ',\n",
    "    b'\\xc2\\xa2'.decode() : ' , ', # ¢\n",
    "    b'\\xe2\\x80\\x8b'.decode() : ' ',\n",
    "    '\\|' : ',',\n",
    "    b'\\xe2\\x80\\x93'.decode() : '-', # the long dash  –\n",
    "    b'\\xe2\\x80\\x94'.decode() : '-', # another long dash\n",
    "    '\\[' : '(',\n",
    "    '\\]' : ')', \n",
    "    '&' : ' and ',\n",
    "    b'\\xe2\\x80\\x9c'.decode() : '\\\"',\n",
    "    b'\\xe2\\x80\\x9d'.decode() : '\\\"',\n",
    "    b'\\xc2\\xbd'.decode() : ' half ',\n",
    "    b'\\xc2\\xbc'.decode() : ' quarter ',\n",
    "    b'\\xe2\\x80\\x99'.decode() : '\\'',\n",
    "    b'\\xe2\\x80\\x98'.decode() : '\\'',\n",
    "    b'\\xc2\\xb4'.decode() : '\\'',\n",
    "    b'\\xc2\\xb5g'.decode() : ' microgram ',\n",
    "    '.' : ' . ',\n",
    "    ',' : ' , '\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#social_terms_organic_relevant_terms dictionary compiled by Ahmed\n",
    "\n",
    "social_terms_organic_relevant_terms = {\n",
    "    'btw' : ' by the way ',\n",
    "    'tl;dr': ' summary ',\n",
    "    'tbsp': ' table spoon ',\n",
    "    'imho': ' in my opinion ',\n",
    "    'imo' : ' in my opinion ',\n",
    "    'oganic': ' organic ',\n",
    "    'orgainc' : ' organic ',\n",
    "    'tsp': ' tea spoon ',\n",
    "    'faqs': ' frequently asked questions ',\n",
    "    'fyi': ' for your information ',\n",
    "    'pestdicides': ' pesticides ',\n",
    "    'pestdicide': ' pesticide ',\n",
    "    'pesiticides': ' pesticides ',\n",
    "    'ogranic': ' organic ',\n",
    "    'pestecides': ' pesticides ',\n",
    "    'nonorganic': ' non organic ',\n",
    "    'pestcides':' pesticides ',\n",
    "    '<3': ' love ',\n",
    "    ' alot ': ' a lot ',\n",
    "    'thier': ' their ',\n",
    "    'breastmilk': ' breast milk ',\n",
    "    'agribusinesses' : ' agricultural businesses ',\n",
    "    '<a href equal \\\"': ' ',\n",
    "    'café': 'cafe'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying English words from data corpus\n",
    "\n",
    "def IsEnglish_dict(y):\n",
    "    counter = 0\n",
    "    for z in y:\n",
    "        if(z in dictwords):\n",
    "            counter +=1 \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifying language using pylibrary\n",
    "\n",
    "from langdetect import detect_langs\n",
    "\n",
    "def EnglishOrGermanOrHindi(string):\n",
    "    try:\n",
    "        res = detect_langs(string)\n",
    "        lang_id = set(' '.join(re.split(r':',str(item))[0] for item in res).split())\n",
    "        if 'id' in lang_id:\n",
    "            return 'id'           \n",
    "        elif 'en' in lang_id:\n",
    "            return 'en'\n",
    "        elif 'de' in lang_id:\n",
    "            return 'de'\n",
    "        return None\n",
    "    except:\n",
    "        return None\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and filtering comments\n",
    "\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "\n",
    "def filter_comments(maindf):\n",
    "    \n",
    "    #Reading non empty and length greater than 15 characters comments\n",
    "    filterdf = pd.DataFrame(maindf[(maindf.comment_text!='') & (maindf.comment_text.apply(len) > 15)]['comment_text'])     \n",
    "    \n",
    "    #Adding new columns for filter computation\n",
    "    filterdf['tidy_comment_text'] = filterdf['split_comment_text'] = filterdf['no_words'] = filterdf['no_English_count'] = filterdf['ratio'] = filterdf['is_English_dict'] = filterdf['language']  = filterdf['is_English_py_pkg'] = filterdf['is_German_py_pkg'] = filterdf['is_Hindi_py_pkg'] = ''\n",
    "        \n",
    "    #Replacing multiple punctuations with single\n",
    "    filterdf.replace({ r'\\A\\s+|\\s+\\Z': '', '\\n' : '. ', r'\\.+': '.', r'\\,+': ',', r'\\-+': '-', r\"\\'+\": \"'\", r'\\!+': '!', r'\\?+': '?', r'\\^+': '^', r'\\#+': '#'}, regex=True, inplace=True)\n",
    "    \n",
    "    #Replacing Devanagari(Hindi scripts) with white space\n",
    "    filterdf['comment_text'] = [(re.sub('\\  +', ' ', (' '.join([(' ' if bool(re.search(r'\\p{Devanagari}',y)) else y.strip()) for y in x.split()]).strip() if bool(re.search(r'\\p{Devanagari}+',x)) else x.strip()))) for x in filterdf['comment_text']]\n",
    "\n",
    "    #Replacing contractions compiled by Ahmed\n",
    "    filterdf['comment_text'] = [' '.join(contractions[p] if p in contractions else (contractions[p.lower()] if p.lower() in contractions else p) for p in y.split()) for y in filterdf['comment_text']]\n",
    "\n",
    "    #social_terms_organic_relevant_terms dictionary compiled by Ahmed\n",
    "    filterdf['comment_text'] = [' '.join(social_terms_organic_relevant_terms[p.lower()] if p.lower() in social_terms_organic_relevant_terms else p for p in y.split()) for y in filterdf['comment_text']]\n",
    "\n",
    "    #Replacement dictionary compiled by Ahmed\n",
    "    filterdf['comment_text'] = [re.sub('\\  +', ' ', ' '.join(replacement_dict[p] if p in replacement_dict else p for p in y.split())) for y in filterdf['comment_text']]\n",
    "\n",
    "    #White spacing url links\n",
    "    filterdf['tidy_comment_text'] = [re.split(r'http|https|www',x)[0] for x in filterdf['comment_text']]\n",
    "    \n",
    "    #Filtering only words\n",
    "    filterdf['tidy_comment_text'] = [re.sub(r\"[^\\P{P}']+\", ' ', x).strip() for x in filterdf['tidy_comment_text']]\n",
    "    \n",
    "    filterdf['split_comment_text'] = [x.lower().split() for x in filterdf['tidy_comment_text']]\n",
    "    \n",
    "    filterdf['no_words'] = [len(x) for x in filterdf['split_comment_text']]\n",
    "    \n",
    "    #Checking English words from dictionary\n",
    "    filterdf['no_English_count'] = [IsEnglish_dict(x) for x in filterdf['split_comment_text']]\n",
    "    \n",
    "    filterdf['ratio'] = filterdf['no_English_count'] / filterdf['no_words']\n",
    "    \n",
    "    #Count of English dictionary words with 50% cutoff threshold\n",
    "    filterdf['is_English_dict'] =  [1 if x > 0.5 else 0 for x in filterdf['ratio']]\n",
    "    \n",
    "    #Identifyting language using langdetect python library\n",
    "    filterdf['language'] =  [EnglishOrGermanOrHindi(x) for x in filterdf['comment_text']]\n",
    "       \n",
    "    filterdf['is_English_py_pkg'] = [1 if x=='en' else 0 for x in filterdf['language']]\n",
    "    \n",
    "    filterdf['is_German_py_pkg'] = [1 if x=='de' else 0 for x in filterdf['language']]\n",
    "    \n",
    "    filterdf['is_Hindi_py_pkg'] = [1 if x=='id' else 0 for x in filterdf['language']]\n",
    "    \n",
    "    #Again replacing multiple punctuations with single\n",
    "    filterdf.replace({r'\\.+': '.', r'\\,+': ',', r'\\-+': '-', r\"\\'+\": \"'\", r'\\!+': '!', r'\\?+': '?', r'\\^+': '^', r'\\#+': '#', r'\\  +': ' '}, regex=True, inplace=True)    \n",
    "    \n",
    "    #Reading final non empty and length greater than 15 characters comments (post pre-processing)\n",
    "    filterdf1 = filterdf[(filterdf.comment_text!='') & (filterdf.comment_text.apply(len) > 15)]\n",
    "    \n",
    "    #Removing only the auto blacklisted comments\n",
    "    #Then exporting just the 'comments_text' column after removing duplicates\n",
    "    final_filterdf = filterdf1[~(filterdf1['is_English_dict'].isin(['0']) & filterdf1['is_English_py_pkg'].isin(['0']))][['comment_text']].drop_duplicates()\n",
    "       \n",
    "    return final_filterdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unbiased_forum_data count:  (107599, 12)\n",
      "unbiased_news_data count:  (101711, 12)\n",
      "biased_data count:  (306037, 12)\n",
      "jsons_data count:  (515347, 12)\n",
      "Final count (125205, 1)\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "# Finalizing data for initial training\n",
    "\n",
    "# Load your comments file as pandas dataframe 'jsons_data'. ENSURE it has a COLUMN named 'comment_text'\n",
    "directory = 'C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/raw_source_data/english'\n",
    "\n",
    "unbiased_forum = directory + \"/unbiased/Forum/output/final_df.pkl\" \n",
    "unbiased_news = directory + \"/unbiased/newssites/output/final_df.pkl\" \n",
    "biased = directory + \"/biased/output/final_df.pkl\"\n",
    "\n",
    "unbiased_forum_data = pd.read_pickle(unbiased_forum) \n",
    "unbiased_news_data = pd.read_pickle(unbiased_news) \n",
    "biased_data = pd.read_pickle(biased) \n",
    "\n",
    "print('unbiased_forum_data count: ', unbiased_forum_data.shape)\n",
    "print('unbiased_news_data count: ', unbiased_news_data.shape)\n",
    "print('biased_data count: ', biased_data.shape)\n",
    "\n",
    "#Concatenate English data\n",
    "jsons_data = pd.DataFrame(np.concatenate([unbiased_forum_data.values, unbiased_news_data.values, biased_data.values]), columns=unbiased_forum_data.columns)\n",
    "\n",
    "print('jsons_data count: ', jsons_data.shape)\n",
    "\n",
    "#Filtering relevant comments\n",
    "json_filtered = filter_comments(jsons_data[(jsons_data.relevant==1)])\n",
    "\n",
    "\n",
    "#Exporting the filtered comment to text file\n",
    "file_output_txt_filename = directory + \"/output/english_filtered_comments.txt\" \n",
    "json_filtered.to_csv(file_output_txt_filename, header=False, index=False, sep='\\t', mode='w+')\n",
    "\n",
    "print('Final count',json_filtered.shape)\n",
    "print('completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author_ID</th>\n",
       "      <th>Author_name</th>\n",
       "      <th>Comment_number</th>\n",
       "      <th>Sentence_number</th>\n",
       "      <th>Domain_Relevance</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Source_file</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thanks for the thoughtful response.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I think we actually have a lot of common groun...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All I want to emphasize are my main points: Pr...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>p</td>\n",
       "      <td>cg</td>\n",
       "      <td>pp</td>\n",
       "      <td>Industrialization is everything about producti...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>cg-pp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Creating jobs at the expense of efficiency is ...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The externalities associated with industrializ...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>g</td>\n",
       "      <td>g</td>\n",
       "      <td>'Organic' agriculture goes along with that the...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>g-g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agriculture was pretty destructive from the 19...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There's been steady 'sustainable' improvements...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This happened before organic took off.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The organic push has a lot of value because it...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A close friend of mine does some great work wi...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The farm boys and farm girls I work with aren'...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>But they aren't hand weeding either.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'Walkin' the beans' is not something anybody i...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They know how to maintain equipment, breed pla...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If they were hand weeding or hand harvesting, ...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Justin-Ma</td>\n",
       "      <td>Justin Ma</td>\n",
       "      <td>521</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There is actually a shortage of skilled farm l...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>sumit</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>n</td>\n",
       "      <td>cp</td>\n",
       "      <td>a</td>\n",
       "      <td>It isn't innate in chickens to be \"disease pro...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>cp-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I think if you compare the health of a small r...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now, compare it a small USA city to Baku, Azer...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I think you'll find a huge difference in citiz...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>n</td>\n",
       "      <td>cp</td>\n",
       "      <td>a</td>\n",
       "      <td>What looks more healthy to you: factory farmed...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>cp-a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They have no muscle tone as they can't move th...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>If you took them out of their cages they would...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>They have probably never flown in their lives.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Because of they crowded, very unhealthy condit...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>p</td>\n",
       "      <td>cf</td>\n",
       "      <td>g</td>\n",
       "      <td>We currently only have 8 laying hens but even ...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>cf-g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>p</td>\n",
       "      <td>cf</td>\n",
       "      <td>g</td>\n",
       "      <td>When it warms up we'll average about 7 a day.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>cf-g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Mick-Stute</td>\n",
       "      <td>Mick Stute</td>\n",
       "      <td>1286</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>p</td>\n",
       "      <td>cp</td>\n",
       "      <td>g</td>\n",
       "      <td>That's more eggs then we can eat as a family o...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>florian</td>\n",
       "      <td>cp-g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8793</th>\n",
       "      <td>Scott-Hoversten</td>\n",
       "      <td>Scott Hoversten</td>\n",
       "      <td>1793</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And the weather change probably helps grow mos...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8794</th>\n",
       "      <td>Jeremy-Jaffe-2</td>\n",
       "      <td>Jeremy Jaffe</td>\n",
       "      <td>1844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the word Biologique is the French equivalent o...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8795</th>\n",
       "      <td>Atul-Chaudhary-26</td>\n",
       "      <td>Atul Chaudhary</td>\n",
       "      <td>1853</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>First of all your main focus should be to scor...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8796</th>\n",
       "      <td>Atul-Chaudhary-26</td>\n",
       "      <td>Atul Chaudhary</td>\n",
       "      <td>1853</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Now come to he main organic chemistry section ...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8797</th>\n",
       "      <td>Atul-Chaudhary-26</td>\n",
       "      <td>Atul Chaudhary</td>\n",
       "      <td>1853</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just go through the notes make sure not to lea...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8798</th>\n",
       "      <td>Atul-Chaudhary-26</td>\n",
       "      <td>Atul Chaudhary</td>\n",
       "      <td>1853</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I’ll suggest you on my persional experience ju...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8799</th>\n",
       "      <td>Atul-Chaudhary-26</td>\n",
       "      <td>Atul Chaudhary</td>\n",
       "      <td>1853</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>and then to move forward because these chapter...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8800</th>\n",
       "      <td>Atul-Chaudhary-26</td>\n",
       "      <td>Atul Chaudhary</td>\n",
       "      <td>1853</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SO BEST OFF LUCK!</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8801</th>\n",
       "      <td>Tripti-23</td>\n",
       "      <td>Tripti</td>\n",
       "      <td>1854</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 months is sufficient for organic Make separa...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>Tripti-23</td>\n",
       "      <td>Tripti</td>\n",
       "      <td>1854</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In these type of reactions the products are fi...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>Tripti-23</td>\n",
       "      <td>Tripti</td>\n",
       "      <td>1854</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>These points will be beneficial for you.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>Ranbir-Singh-35</td>\n",
       "      <td>Ranbir Singh</td>\n",
       "      <td>1855</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hi.. Let me tell you.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>Ranbir-Singh-35</td>\n",
       "      <td>Ranbir Singh</td>\n",
       "      <td>1855</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specially in organic chemistry you need to do ...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>Ranbir-Singh-35</td>\n",
       "      <td>Ranbir Singh</td>\n",
       "      <td>1855</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>For board's I did Pradeep's book to get in dep...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8807</th>\n",
       "      <td>Ranbir-Singh-35</td>\n",
       "      <td>Ranbir Singh</td>\n",
       "      <td>1855</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It can be done in two months .</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8808</th>\n",
       "      <td>Ranbir-Singh-35</td>\n",
       "      <td>Ranbir Singh</td>\n",
       "      <td>1855</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Focus on just these two books and more on NCERT .</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8809</th>\n",
       "      <td>Ranbir-Singh-35</td>\n",
       "      <td>Ranbir Singh</td>\n",
       "      <td>1855</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Back exercises of only NCERT is important as i...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8810</th>\n",
       "      <td>Ranbir-Singh-35</td>\n",
       "      <td>Ranbir Singh</td>\n",
       "      <td>1855</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Best of luck and study chemistry daily as it i...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8811</th>\n",
       "      <td>Madhav-Thakker</td>\n",
       "      <td>Madhav Thakker</td>\n",
       "      <td>1856</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Organic chemistry is not as difficult as it se...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8812</th>\n",
       "      <td>Madhav-Thakker</td>\n",
       "      <td>Madhav Thakker</td>\n",
       "      <td>1856</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once you get onto the subject you will find it...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8813</th>\n",
       "      <td>Madhav-Thakker</td>\n",
       "      <td>Madhav Thakker</td>\n",
       "      <td>1856</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boards level og organic is not very high.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8814</th>\n",
       "      <td>Madhav-Thakker</td>\n",
       "      <td>Madhav Thakker</td>\n",
       "      <td>1856</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I will strongly recommend NCERT book for organic.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8815</th>\n",
       "      <td>Madhav-Thakker</td>\n",
       "      <td>Madhav Thakker</td>\n",
       "      <td>1856</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boards will never go out of NCERT.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8816</th>\n",
       "      <td>Vishnu-Vardhan-Reddy-108</td>\n",
       "      <td>Vishnu Vardhan Reddy</td>\n",
       "      <td>1874</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Is there any internship in organic farming ??</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8817</th>\n",
       "      <td>Vishnu-Vardhan-Reddy-108</td>\n",
       "      <td>Vishnu Vardhan Reddy</td>\n",
       "      <td>1874</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I was an engineering final year graduate , had...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8818</th>\n",
       "      <td>Janice-Person</td>\n",
       "      <td>Janice Person</td>\n",
       "      <td>1882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This label indicates it is certified organic b...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8819</th>\n",
       "      <td>Janice-Person</td>\n",
       "      <td>Janice Person</td>\n",
       "      <td>1882</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;URL&gt;\" In the US, it is the only official logo...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8820</th>\n",
       "      <td>Chander-Asrani</td>\n",
       "      <td>Chander Asrani</td>\n",
       "      <td>1918</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I respectfully say, if you have thyroid proble...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821</th>\n",
       "      <td>Chander-Asrani</td>\n",
       "      <td>Chander Asrani</td>\n",
       "      <td>1918</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>There are no organic medicines.</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8822</th>\n",
       "      <td>Chander-Asrani</td>\n",
       "      <td>Chander Asrani</td>\n",
       "      <td>1918</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Even doctors don't have time to convince peopl...</td>\n",
       "      <td>quora.json</td>\n",
       "      <td>abilasha</td>\n",
       "      <td>nan-nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8823 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Author_ID           Author_name  Comment_number  \\\n",
       "0                    Justin-Ma             Justin Ma             521   \n",
       "1                    Justin-Ma             Justin Ma             521   \n",
       "2                    Justin-Ma             Justin Ma             521   \n",
       "3                    Justin-Ma             Justin Ma             521   \n",
       "4                    Justin-Ma             Justin Ma             521   \n",
       "5                    Justin-Ma             Justin Ma             521   \n",
       "6                    Justin-Ma             Justin Ma             521   \n",
       "7                    Justin-Ma             Justin Ma             521   \n",
       "8                    Justin-Ma             Justin Ma             521   \n",
       "9                    Justin-Ma             Justin Ma             521   \n",
       "10                   Justin-Ma             Justin Ma             521   \n",
       "11                   Justin-Ma             Justin Ma             521   \n",
       "12                   Justin-Ma             Justin Ma             521   \n",
       "13                   Justin-Ma             Justin Ma             521   \n",
       "14                   Justin-Ma             Justin Ma             521   \n",
       "15                   Justin-Ma             Justin Ma             521   \n",
       "16                   Justin-Ma             Justin Ma             521   \n",
       "17                   Justin-Ma             Justin Ma             521   \n",
       "18                  Mick-Stute            Mick Stute            1286   \n",
       "19                  Mick-Stute            Mick Stute            1286   \n",
       "20                  Mick-Stute            Mick Stute            1286   \n",
       "21                  Mick-Stute            Mick Stute            1286   \n",
       "22                  Mick-Stute            Mick Stute            1286   \n",
       "23                  Mick-Stute            Mick Stute            1286   \n",
       "24                  Mick-Stute            Mick Stute            1286   \n",
       "25                  Mick-Stute            Mick Stute            1286   \n",
       "26                  Mick-Stute            Mick Stute            1286   \n",
       "27                  Mick-Stute            Mick Stute            1286   \n",
       "28                  Mick-Stute            Mick Stute            1286   \n",
       "29                  Mick-Stute            Mick Stute            1286   \n",
       "...                        ...                   ...             ...   \n",
       "8793           Scott-Hoversten       Scott Hoversten            1793   \n",
       "8794            Jeremy-Jaffe-2          Jeremy Jaffe            1844   \n",
       "8795         Atul-Chaudhary-26        Atul Chaudhary            1853   \n",
       "8796         Atul-Chaudhary-26        Atul Chaudhary            1853   \n",
       "8797         Atul-Chaudhary-26        Atul Chaudhary            1853   \n",
       "8798         Atul-Chaudhary-26        Atul Chaudhary            1853   \n",
       "8799         Atul-Chaudhary-26        Atul Chaudhary            1853   \n",
       "8800         Atul-Chaudhary-26        Atul Chaudhary            1853   \n",
       "8801                 Tripti-23                Tripti            1854   \n",
       "8802                 Tripti-23                Tripti            1854   \n",
       "8803                 Tripti-23                Tripti            1854   \n",
       "8804           Ranbir-Singh-35          Ranbir Singh            1855   \n",
       "8805           Ranbir-Singh-35          Ranbir Singh            1855   \n",
       "8806           Ranbir-Singh-35          Ranbir Singh            1855   \n",
       "8807           Ranbir-Singh-35          Ranbir Singh            1855   \n",
       "8808           Ranbir-Singh-35          Ranbir Singh            1855   \n",
       "8809           Ranbir-Singh-35          Ranbir Singh            1855   \n",
       "8810           Ranbir-Singh-35          Ranbir Singh            1855   \n",
       "8811            Madhav-Thakker        Madhav Thakker            1856   \n",
       "8812            Madhav-Thakker        Madhav Thakker            1856   \n",
       "8813            Madhav-Thakker        Madhav Thakker            1856   \n",
       "8814            Madhav-Thakker        Madhav Thakker            1856   \n",
       "8815            Madhav-Thakker        Madhav Thakker            1856   \n",
       "8816  Vishnu-Vardhan-Reddy-108  Vishnu Vardhan Reddy            1874   \n",
       "8817  Vishnu-Vardhan-Reddy-108  Vishnu Vardhan Reddy            1874   \n",
       "8818             Janice-Person         Janice Person            1882   \n",
       "8819             Janice-Person         Janice Person            1882   \n",
       "8820            Chander-Asrani        Chander Asrani            1918   \n",
       "8821            Chander-Asrani        Chander Asrani            1918   \n",
       "8822            Chander-Asrani        Chander Asrani            1918   \n",
       "\n",
       "      Sentence_number  Domain_Relevance Sentiment Entity Attribute  \\\n",
       "0                   1                 0       NaN    NaN       NaN   \n",
       "1                   2                 0       NaN    NaN       NaN   \n",
       "2                   3                 0       NaN    NaN       NaN   \n",
       "3                   4                 9         p     cg        pp   \n",
       "4                   5                 0       NaN    NaN       NaN   \n",
       "5                   6                 0       NaN    NaN       NaN   \n",
       "6                   7                 9         0      g         g   \n",
       "7                   8                 0       NaN    NaN       NaN   \n",
       "8                   9                 0       NaN    NaN       NaN   \n",
       "9                  10                 0       NaN    NaN       NaN   \n",
       "10                 11                 0       NaN    NaN       NaN   \n",
       "11                 12                 0       NaN    NaN       NaN   \n",
       "12                 13                 0       NaN    NaN       NaN   \n",
       "13                 14                 0       NaN    NaN       NaN   \n",
       "14                 15                 0       NaN    NaN       NaN   \n",
       "15                 16                 0       NaN    NaN       NaN   \n",
       "16                 17                 0       NaN    NaN       NaN   \n",
       "17                 18                 0       NaN    NaN       NaN   \n",
       "18                  1                 9         n     cp         a   \n",
       "19                  2                 0       NaN    NaN       NaN   \n",
       "20                  3                 0       NaN    NaN       NaN   \n",
       "21                  4                 0       NaN    NaN       NaN   \n",
       "22                  5                 9         n     cp         a   \n",
       "23                  6                 0       NaN    NaN       NaN   \n",
       "24                  7                 0       NaN    NaN       NaN   \n",
       "25                  8                 0       NaN    NaN       NaN   \n",
       "26                  9                 0       NaN    NaN       NaN   \n",
       "27                 10                 9         p     cf         g   \n",
       "28                 11                 9         p     cf         g   \n",
       "29                 12                 9         p     cp         g   \n",
       "...               ...               ...       ...    ...       ...   \n",
       "8793                2                 0       NaN    NaN       NaN   \n",
       "8794                1                 0       NaN    NaN       NaN   \n",
       "8795                1                 0       NaN    NaN       NaN   \n",
       "8796                2                 0       NaN    NaN       NaN   \n",
       "8797                3                 0       NaN    NaN       NaN   \n",
       "8798                4                 0       NaN    NaN       NaN   \n",
       "8799                5                 0       NaN    NaN       NaN   \n",
       "8800                6                 0       NaN    NaN       NaN   \n",
       "8801                1                 0       NaN    NaN       NaN   \n",
       "8802                2                 0       NaN    NaN       NaN   \n",
       "8803                3                 0       NaN    NaN       NaN   \n",
       "8804                1                 0       NaN    NaN       NaN   \n",
       "8805                2                 0       NaN    NaN       NaN   \n",
       "8806                3                 0       NaN    NaN       NaN   \n",
       "8807                4                 0       NaN    NaN       NaN   \n",
       "8808                5                 0       NaN    NaN       NaN   \n",
       "8809                6                 0       NaN    NaN       NaN   \n",
       "8810                7                 0       NaN    NaN       NaN   \n",
       "8811                1                 0       NaN    NaN       NaN   \n",
       "8812                2                 0       NaN    NaN       NaN   \n",
       "8813                3                 0       NaN    NaN       NaN   \n",
       "8814                4                 0       NaN    NaN       NaN   \n",
       "8815                5                 0       NaN    NaN       NaN   \n",
       "8816                1                 0       NaN    NaN       NaN   \n",
       "8817                2                 0       NaN    NaN       NaN   \n",
       "8818                1                 0       NaN    NaN       NaN   \n",
       "8819                2                 0       NaN    NaN       NaN   \n",
       "8820                1                 0       NaN    NaN       NaN   \n",
       "8821                2                 0       NaN    NaN       NaN   \n",
       "8822                3                 0       NaN    NaN       NaN   \n",
       "\n",
       "                                               Sentence Source_file Annotator  \\\n",
       "0                   Thanks for the thoughtful response.  quora.json     sumit   \n",
       "1     I think we actually have a lot of common groun...  quora.json     sumit   \n",
       "2     All I want to emphasize are my main points: Pr...  quora.json     sumit   \n",
       "3     Industrialization is everything about producti...  quora.json     sumit   \n",
       "4     Creating jobs at the expense of efficiency is ...  quora.json     sumit   \n",
       "5     The externalities associated with industrializ...  quora.json     sumit   \n",
       "6     'Organic' agriculture goes along with that the...  quora.json     sumit   \n",
       "7     Agriculture was pretty destructive from the 19...  quora.json     sumit   \n",
       "8     There's been steady 'sustainable' improvements...  quora.json     sumit   \n",
       "9                This happened before organic took off.  quora.json     sumit   \n",
       "10    The organic push has a lot of value because it...  quora.json     sumit   \n",
       "11    A close friend of mine does some great work wi...  quora.json     sumit   \n",
       "12    The farm boys and farm girls I work with aren'...  quora.json     sumit   \n",
       "13                 But they aren't hand weeding either.  quora.json     sumit   \n",
       "14    'Walkin' the beans' is not something anybody i...  quora.json     sumit   \n",
       "15    They know how to maintain equipment, breed pla...  quora.json     sumit   \n",
       "16    If they were hand weeding or hand harvesting, ...  quora.json     sumit   \n",
       "17    There is actually a shortage of skilled farm l...  quora.json     sumit   \n",
       "18    It isn't innate in chickens to be \"disease pro...  quora.json   florian   \n",
       "19    I think if you compare the health of a small r...  quora.json   florian   \n",
       "20    Now, compare it a small USA city to Baku, Azer...  quora.json   florian   \n",
       "21    I think you'll find a huge difference in citiz...  quora.json   florian   \n",
       "22    What looks more healthy to you: factory farmed...  quora.json   florian   \n",
       "23    They have no muscle tone as they can't move th...  quora.json   florian   \n",
       "24    If you took them out of their cages they would...  quora.json   florian   \n",
       "25       They have probably never flown in their lives.  quora.json   florian   \n",
       "26    Because of they crowded, very unhealthy condit...  quora.json   florian   \n",
       "27    We currently only have 8 laying hens but even ...  quora.json   florian   \n",
       "28        When it warms up we'll average about 7 a day.  quora.json   florian   \n",
       "29    That's more eggs then we can eat as a family o...  quora.json   florian   \n",
       "...                                                 ...         ...       ...   \n",
       "8793  And the weather change probably helps grow mos...  quora.json  abilasha   \n",
       "8794  the word Biologique is the French equivalent o...  quora.json  abilasha   \n",
       "8795  First of all your main focus should be to scor...  quora.json  abilasha   \n",
       "8796  Now come to he main organic chemistry section ...  quora.json  abilasha   \n",
       "8797  Just go through the notes make sure not to lea...  quora.json  abilasha   \n",
       "8798  I’ll suggest you on my persional experience ju...  quora.json  abilasha   \n",
       "8799  and then to move forward because these chapter...  quora.json  abilasha   \n",
       "8800                                  SO BEST OFF LUCK!  quora.json  abilasha   \n",
       "8801  2 months is sufficient for organic Make separa...  quora.json  abilasha   \n",
       "8802  In these type of reactions the products are fi...  quora.json  abilasha   \n",
       "8803           These points will be beneficial for you.  quora.json  abilasha   \n",
       "8804                              Hi.. Let me tell you.  quora.json  abilasha   \n",
       "8805  Specially in organic chemistry you need to do ...  quora.json  abilasha   \n",
       "8806  For board's I did Pradeep's book to get in dep...  quora.json  abilasha   \n",
       "8807                     It can be done in two months .  quora.json  abilasha   \n",
       "8808  Focus on just these two books and more on NCERT .  quora.json  abilasha   \n",
       "8809  Back exercises of only NCERT is important as i...  quora.json  abilasha   \n",
       "8810  Best of luck and study chemistry daily as it i...  quora.json  abilasha   \n",
       "8811  Organic chemistry is not as difficult as it se...  quora.json  abilasha   \n",
       "8812  Once you get onto the subject you will find it...  quora.json  abilasha   \n",
       "8813          Boards level og organic is not very high.  quora.json  abilasha   \n",
       "8814  I will strongly recommend NCERT book for organic.  quora.json  abilasha   \n",
       "8815                 Boards will never go out of NCERT.  quora.json  abilasha   \n",
       "8816      Is there any internship in organic farming ??  quora.json  abilasha   \n",
       "8817  I was an engineering final year graduate , had...  quora.json  abilasha   \n",
       "8818  This label indicates it is certified organic b...  quora.json  abilasha   \n",
       "8819  <URL>\" In the US, it is the only official logo...  quora.json  abilasha   \n",
       "8820  I respectfully say, if you have thyroid proble...  quora.json  abilasha   \n",
       "8821                    There are no organic medicines.  quora.json  abilasha   \n",
       "8822  Even doctors don't have time to convince peopl...  quora.json  abilasha   \n",
       "\n",
       "       Aspect  \n",
       "0     nan-nan  \n",
       "1     nan-nan  \n",
       "2     nan-nan  \n",
       "3       cg-pp  \n",
       "4     nan-nan  \n",
       "5     nan-nan  \n",
       "6         g-g  \n",
       "7     nan-nan  \n",
       "8     nan-nan  \n",
       "9     nan-nan  \n",
       "10    nan-nan  \n",
       "11    nan-nan  \n",
       "12    nan-nan  \n",
       "13    nan-nan  \n",
       "14    nan-nan  \n",
       "15    nan-nan  \n",
       "16    nan-nan  \n",
       "17    nan-nan  \n",
       "18       cp-a  \n",
       "19    nan-nan  \n",
       "20    nan-nan  \n",
       "21    nan-nan  \n",
       "22       cp-a  \n",
       "23    nan-nan  \n",
       "24    nan-nan  \n",
       "25    nan-nan  \n",
       "26    nan-nan  \n",
       "27       cf-g  \n",
       "28       cf-g  \n",
       "29       cp-g  \n",
       "...       ...  \n",
       "8793  nan-nan  \n",
       "8794  nan-nan  \n",
       "8795  nan-nan  \n",
       "8796  nan-nan  \n",
       "8797  nan-nan  \n",
       "8798  nan-nan  \n",
       "8799  nan-nan  \n",
       "8800  nan-nan  \n",
       "8801  nan-nan  \n",
       "8802  nan-nan  \n",
       "8803  nan-nan  \n",
       "8804  nan-nan  \n",
       "8805  nan-nan  \n",
       "8806  nan-nan  \n",
       "8807  nan-nan  \n",
       "8808  nan-nan  \n",
       "8809  nan-nan  \n",
       "8810  nan-nan  \n",
       "8811  nan-nan  \n",
       "8812  nan-nan  \n",
       "8813  nan-nan  \n",
       "8814  nan-nan  \n",
       "8815  nan-nan  \n",
       "8816  nan-nan  \n",
       "8817  nan-nan  \n",
       "8818  nan-nan  \n",
       "8819  nan-nan  \n",
       "8820  nan-nan  \n",
       "8821  nan-nan  \n",
       "8822  nan-nan  \n",
       "\n",
       "[8823 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading annotated data\n",
    "import pandas as pd\n",
    "annotatedtrain = pd.read_csv('C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.2/train/dataframe.csv', sep = '|')\n",
    "annotatedtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'p', '0', 'n']\n",
      "Sentiment\n",
      "0    1812\n",
      "n    1375\n",
      "p    1500\n",
      "dtype: int64\n",
      "NaN count (4136, 12)\n",
      "Total count (8823, 12)\n"
     ]
    }
   ],
   "source": [
    "print(annotatedtrain['Sentiment'].unique().tolist())\n",
    "print(annotatedtrain.groupby('Sentiment').size())\n",
    "print('NaN count',annotatedtrain[annotatedtrain['Sentiment'].isna()].shape)\n",
    "print('Total count',annotatedtrain.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'cg', 'g', 'cp', 'cf', 'f', 'p', 'gg', 'cc', 'c']\n",
      "Entity\n",
      "c      289\n",
      "cc      21\n",
      "cf     204\n",
      "cg      41\n",
      "cp     298\n",
      "f      849\n",
      "g     1093\n",
      "gg     257\n",
      "p     1635\n",
      "dtype: int64\n",
      "NaN count (4136, 12)\n",
      "Total count (8823, 12)\n"
     ]
    }
   ],
   "source": [
    "print(annotatedtrain['Entity'].unique().tolist())\n",
    "print(annotatedtrain.groupby('Entity').size())\n",
    "print('NaN count',annotatedtrain[annotatedtrain['Entity'].isna()].shape)\n",
    "print('Total count',annotatedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entity  Sentiment\n",
       "c       0            104\n",
       "        n             80\n",
       "        p            105\n",
       "cc      0              9\n",
       "        n             12\n",
       "cf      0             70\n",
       "        n            100\n",
       "        p             34\n",
       "cg      0             19\n",
       "        n             15\n",
       "        p              7\n",
       "cp      0             93\n",
       "        n            145\n",
       "        p             60\n",
       "f       0            347\n",
       "        n            214\n",
       "        p            288\n",
       "g       0            582\n",
       "        n            253\n",
       "        p            258\n",
       "gg      0            116\n",
       "        n             86\n",
       "        p             55\n",
       "p       0            472\n",
       "        n            470\n",
       "        p            693\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotatedtrain.groupby(['Entity', 'Sentiment']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 'pp', 'g', 'a', 'h', 'c', 's', 'av', 'll', 'e', 'or', 'p', 'q', 't', 'l']\n",
      "Attribute\n",
      "a      104\n",
      "av     112\n",
      "c      632\n",
      "e      235\n",
      "g     1549\n",
      "h      483\n",
      "l       53\n",
      "ll     333\n",
      "or      78\n",
      "p      296\n",
      "pp     130\n",
      "q      311\n",
      "s      199\n",
      "t      172\n",
      "dtype: int64\n",
      "NaN count (4136, 12)\n",
      "Total count (8823, 12)\n"
     ]
    }
   ],
   "source": [
    "print(annotatedtrain['Attribute'].unique().tolist())\n",
    "print(annotatedtrain.groupby('Attribute').size())\n",
    "print('NaN count',annotatedtrain[annotatedtrain['Attribute'].isna()].shape)\n",
    "print('Total count',annotatedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan-nan', 'cg-pp', 'g-g', 'cp-a', 'cf-g', 'cp-g', 'cf-a', 'cp-h', 'f-c', 'p-s', 'cf-av', 'cp-c', 'f-g', 'f-pp', 'gg-g', 'gg-s', 'cc-g', 'cc-s', 'gg-h', 'g-ll', 'cg-e', 'f-a', 'f-ll', 'cf-or', 'cf-pp', 'p-h', 'p-c', 'cp-s', 'cc-c', 'cc-e', 'p-p', 'f-e', 'f-h', 'cp-e', 'gg-e', 'cc-pp', 'p-g', 'p-ll', 'c-q', 'c-pp', 'f-or', 'cf-ll', 'cg-or', 'cg-ll', 'cc-t', 'c-p', 'g-av', 'cc-av', 'g-h', 'c-g', 'p-a', 'cf-e', 'cf-s', 'cc-a', 'g-e', 'cg-p', 'p-or', 'cp-or', 'gg-or', 'p-e', 'c-s', 'c-e', 'p-l', 'cp-l', 'cp-pp', 'cf-q', 'cp-t', 'c-t', 'p-t', 'c-ll', 'c-av', 'f-s', 'c-a', 'c-or', 'g-c', 'cc-ll', 'cf-c', 'p-av', 'g-p', 'c-c', 'cg-h', 'cg-c', 'g-t', 'cf-t', 'p-q', 'cp-ll', 'c-l', 'c-h', 'cg-s', 'gg-t', 'f-t', 'gg-c', 'f-q', 'gg-q', 'g-s', 'cp-q', 'cf-h', 'f-av', 'cp-av', 'g-l', 'p-pp', 'f-p', 'gg-p', 'gg-pp', 'cg-q', 'cf-p', 'cp-p', 'g-q', 'gg-ll', 'f-l', 'g-pp', 'g-or', 'cg-g', 'g-a']\n",
      "Aspect\n",
      "c-a           2\n",
      "c-av         40\n",
      "c-c           4\n",
      "c-e           6\n",
      "c-g         127\n",
      "c-h           6\n",
      "c-l           4\n",
      "c-ll         56\n",
      "c-or          5\n",
      "c-p          21\n",
      "c-pp          1\n",
      "c-q          11\n",
      "c-s           4\n",
      "c-t           2\n",
      "cc-a          1\n",
      "cc-av         1\n",
      "cc-c          1\n",
      "cc-e          1\n",
      "cc-g         11\n",
      "cc-ll         3\n",
      "cc-pp         1\n",
      "cc-s          1\n",
      "cc-t          1\n",
      "cf-a         25\n",
      "cf-av         1\n",
      "cf-c         65\n",
      "cf-e         30\n",
      "cf-g         44\n",
      "cf-h          2\n",
      "cf-ll         1\n",
      "           ... \n",
      "g-pp         14\n",
      "g-q          28\n",
      "g-s          24\n",
      "g-t          22\n",
      "gg-c         10\n",
      "gg-e         11\n",
      "gg-g        130\n",
      "gg-h         30\n",
      "gg-ll        14\n",
      "gg-or         3\n",
      "gg-p          7\n",
      "gg-pp         9\n",
      "gg-q          9\n",
      "gg-s         31\n",
      "gg-t          3\n",
      "nan-nan    4136\n",
      "p-a           7\n",
      "p-av         37\n",
      "p-c         192\n",
      "p-e          43\n",
      "p-g         308\n",
      "p-h         293\n",
      "p-l          24\n",
      "p-ll        127\n",
      "p-or         40\n",
      "p-p         152\n",
      "p-pp          9\n",
      "p-q         202\n",
      "p-s          74\n",
      "p-t         127\n",
      "Length: 114, dtype: int64\n",
      "NaN count (0, 12)\n",
      "Total count (8823, 12)\n"
     ]
    }
   ],
   "source": [
    "print(annotatedtrain['Aspect'].unique().tolist())\n",
    "print(annotatedtrain.groupby('Aspect').size())\n",
    "print('NaN count',annotatedtrain[annotatedtrain['Aspect'].isna()].shape)\n",
    "print('Total count',annotatedtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic full exported... Shape:  (3544,)\n",
      "Organic full positive exported... Shape:  (1195,)\n",
      "Organic full negative exported... Shape:  (932,)\n",
      "Organic full neutral exported... Shape:  (1468,)\n",
      "Organic general exported... Shape:  (1040,)\n",
      "Organic general positive exported... Shape:  (241,)\n",
      "Organic general negative exported... Shape:  (240,)\n",
      "Organic general neutral exported... Shape:  (567,)\n",
      "Organic products exported... Shape:  (1493,)\n",
      "Organic products positive exported... Shape:  (621,)\n",
      "Organic products negative exported... Shape:  (432,)\n",
      "Organic products neutral exported... Shape:  (465,)\n",
      "Organic farmers exported... Shape:  (806,)\n",
      "Organic farmers positive exported... Shape:  (261,)\n",
      "Organic farmers negative exported... Shape:  (207,)\n",
      "Organic farmers neutral exported... Shape:  (343,)\n",
      "Organic companies exported... Shape:  (264,)\n",
      "Organic companies positive exported... Shape:  (96,)\n",
      "Organic companies negative exported... Shape:  (71,)\n",
      "Organic companies neutral exported... Shape:  (101,)\n"
     ]
    }
   ],
   "source": [
    "#Generating finetune data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "fine_tune_folder = 'C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.2/train/'\n",
    "fine_tune_file = fine_tune_folder + \"dataframe.csv\"\n",
    "annotatedtrain = pd.read_csv(fine_tune_file, sep = '|')\n",
    "\n",
    "#Organic full\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_full.txt\"\n",
    "fine_tune_organic_full = annotatedtrain[annotatedtrain.Entity.isin (['g','p', 'f', 'c'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_full.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic full exported... Shape: ', fine_tune_organic_full.shape)\n",
    "\n",
    "#Organic full positive\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_full_positive.txt\"\n",
    "fine_tune_organic_full_positive = annotatedtrain[annotatedtrain.Entity.isin (['g','p', 'f', 'c']) & annotatedtrain.Sentiment.isin(['p'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_full_positive.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic full positive exported... Shape: ', fine_tune_organic_full_positive.shape)\n",
    "\n",
    "#Organic full negative\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_full_negative.txt\"\n",
    "fine_tune_organic_full_negative = annotatedtrain[annotatedtrain.Entity.isin (['g','p', 'f', 'c']) & annotatedtrain.Sentiment.isin(['n'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_full_negative.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic full negative exported... Shape: ', fine_tune_organic_full_negative.shape)\n",
    "\n",
    "#Organic full neutral\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_full_neutral.txt\"\n",
    "fine_tune_organic_full_neutral = annotatedtrain[annotatedtrain.Entity.isin (['g','p', 'f', 'c']) & annotatedtrain.Sentiment.isin(['0'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_full_neutral.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic full neutral exported... Shape: ', fine_tune_organic_full_neutral.shape)\n",
    "\n",
    "\n",
    "############################################################################\n",
    "\n",
    "#Organic general\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_general.txt\"\n",
    "fine_tune_organic_general = annotatedtrain[annotatedtrain.Entity.isin (['g'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_general.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic general exported... Shape: ', fine_tune_organic_general.shape)\n",
    "\n",
    "#Organic general positive\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_general_positive.txt\"\n",
    "fine_tune_organic_general_positive = annotatedtrain[annotatedtrain.Entity.isin (['g']) & annotatedtrain.Sentiment.isin(['p'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_general_positive.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic general positive exported... Shape: ', fine_tune_organic_general_positive.shape)\n",
    "\n",
    "#Organic general negative\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_general_negative.txt\"\n",
    "fine_tune_organic_general_negative = annotatedtrain[annotatedtrain.Entity.isin (['g']) & annotatedtrain.Sentiment.isin(['n'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_general_negative.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic general negative exported... Shape: ', fine_tune_organic_general_negative.shape)\n",
    "\n",
    "#Organic general neutral\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_general_neutral.txt\"\n",
    "fine_tune_organic_general_neutral = annotatedtrain[annotatedtrain.Entity.isin (['g']) & annotatedtrain.Sentiment.isin(['0'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_general_neutral.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic general neutral exported... Shape: ', fine_tune_organic_general_neutral.shape)\n",
    "\n",
    "\n",
    "############################################################################\n",
    "\n",
    "#Organic products\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_products.txt\"\n",
    "fine_tune_organic_products = annotatedtrain[annotatedtrain.Entity.isin (['p'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_products.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic products exported... Shape: ', fine_tune_organic_products.shape)\n",
    "\n",
    "#Organic products positive\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_products_positive.txt\"\n",
    "fine_tune_organic_products_positive = annotatedtrain[annotatedtrain.Entity.isin (['p']) & annotatedtrain.Sentiment.isin(['p'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_products_positive.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic products positive exported... Shape: ', fine_tune_organic_products_positive.shape)\n",
    "\n",
    "#Organic products negative\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_products_negative.txt\"\n",
    "fine_tune_organic_products_negative = annotatedtrain[annotatedtrain.Entity.isin (['p']) & annotatedtrain.Sentiment.isin(['n'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_products_negative.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic products negative exported... Shape: ', fine_tune_organic_products_negative.shape)\n",
    "\n",
    "#Organic products neutral\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_products_neutral.txt\"\n",
    "fine_tune_organic_products_neutral = annotatedtrain[annotatedtrain.Entity.isin (['p']) & annotatedtrain.Sentiment.isin(['0'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_products_neutral.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic products neutral exported... Shape: ', fine_tune_organic_products_neutral.shape)\n",
    "\n",
    "\n",
    "############################################################################\n",
    "\n",
    "#Organic farmers\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_farmers.txt\"\n",
    "fine_tune_organic_farmers = annotatedtrain[annotatedtrain.Entity.isin (['f'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_farmers.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic farmers exported... Shape: ', fine_tune_organic_farmers.shape)\n",
    "\n",
    "#Organic farmers positive\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_farmers_positive.txt\"\n",
    "fine_tune_organic_farmers_positive = annotatedtrain[annotatedtrain.Entity.isin (['f']) & annotatedtrain.Sentiment.isin(['p'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_farmers_positive.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic farmers positive exported... Shape: ', fine_tune_organic_farmers_positive.shape)\n",
    "\n",
    "#Organic farmers negative\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_farmers_negative.txt\"\n",
    "fine_tune_organic_farmers_negative = annotatedtrain[annotatedtrain.Entity.isin (['f']) & annotatedtrain.Sentiment.isin(['n'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_farmers_negative.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic farmers negative exported... Shape: ', fine_tune_organic_farmers_negative.shape)\n",
    "\n",
    "#Organic farmers neutral\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_farmers_neutral.txt\"\n",
    "fine_tune_organic_farmers_neutral = annotatedtrain[annotatedtrain.Entity.isin (['f']) & annotatedtrain.Sentiment.isin(['0'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_farmers_neutral.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic farmers neutral exported... Shape: ', fine_tune_organic_farmers_neutral.shape)\n",
    "\n",
    "\n",
    "############################################################################\n",
    "\n",
    "#Organic companies\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_companies.txt\"\n",
    "fine_tune_organic_companies = annotatedtrain[annotatedtrain.Entity.isin (['c'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_companies.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic companies exported... Shape: ', fine_tune_organic_companies.shape)\n",
    "\n",
    "#Organic companies positive\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_companies_positive.txt\"\n",
    "fine_tune_organic_companies_positive = annotatedtrain[annotatedtrain.Entity.isin (['c']) & annotatedtrain.Sentiment.isin(['p'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_companies_positive.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic companies positive exported... Shape: ', fine_tune_organic_companies_positive.shape)\n",
    "\n",
    "#Organic companies negative\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_companies_negative.txt\"\n",
    "fine_tune_organic_companies_negative = annotatedtrain[annotatedtrain.Entity.isin (['c']) & annotatedtrain.Sentiment.isin(['n'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_companies_negative.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic companies negative exported... Shape: ', fine_tune_organic_companies_negative.shape)\n",
    "\n",
    "#Organic companies neutral\n",
    "file_output = fine_tune_folder + \"output/fine_tune_organic_companies_neutral.txt\"\n",
    "fine_tune_organic_companies_neutral = annotatedtrain[annotatedtrain.Entity.isin (['c']) & annotatedtrain.Sentiment.isin(['0'])]['Sentence'].drop_duplicates()\n",
    "fine_tune_organic_companies_neutral.to_csv(file_output, header=False, index=False, sep='\\t', mode='w+')\n",
    "print('Organic companies neutral exported... Shape: ', fine_tune_organic_companies_neutral.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning of train data\n",
    "\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "annotatedtrain = pd.read_csv('C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.2/train/dataframe.csv', sep = '|')\n",
    "\n",
    "#Replacing contractions compiled by Ahmed\n",
    "annotatedtrain['Sentence'] = [' '.join(contractions[p] if p in contractions else (contractions[p.lower()] if p.lower() in contractions else p) for p in y.split()) for y in annotatedtrain['Sentence']]\n",
    "\n",
    "#social_terms_organic_relevant_terms dictionary compiled by Ahmed\n",
    "annotatedtrain['Sentence'] = [' '.join(social_terms_organic_relevant_terms[p.lower()] if p.lower() in social_terms_organic_relevant_terms else p for p in y.split()) for y in annotatedtrain['Sentence']]\n",
    "\n",
    "#Replacement dictionary compiled by Ahmed\n",
    "annotatedtrain['Sentence'] = [re.sub('\\  +', ' ', ' '.join(replacement_dict[p] if p in replacement_dict else p for p in y.split())) for y in annotatedtrain['Sentence']]\n",
    "\n",
    "annotatedtrain.to_csv('C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.2/train/new/dataframe.csv', header=True, index=False, sep='|', mode='w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning of test data\n",
    "\n",
    "import pandas as pd\n",
    "annotatedtest = pd.read_csv('C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.2/test/dataframe.csv', sep = '|')\n",
    "\n",
    "#Replacing contractions compiled by Ahmed\n",
    "annotatedtest['Sentence'] = [' '.join(contractions[p] if p in contractions else (contractions[p.lower()] if p.lower() in contractions else p) for p in y.split()) for y in annotatedtest['Sentence']]\n",
    "\n",
    "#social_terms_organic_relevant_terms dictionary compiled by Ahmed\n",
    "annotatedtest['Sentence'] = [' '.join(social_terms_organic_relevant_terms[p.lower()] if p.lower() in social_terms_organic_relevant_terms else p for p in y.split()) for y in annotatedtest['Sentence']]\n",
    "\n",
    "#Replacement dictionary compiled by Ahmed\n",
    "annotatedtest['Sentence'] = [re.sub('\\  +', ' ', ' '.join(replacement_dict[p] if p in replacement_dict else p for p in y.split())) for y in annotatedtest['Sentence']]\n",
    "\n",
    "annotatedtest.to_csv('C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.2/test/new/dataframe.csv', header=True, index=False, sep='|', mode='w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning of validation data\n",
    "\n",
    "import pandas as pd\n",
    "annotatedval = pd.read_csv('C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.2/validation/dataframe.csv', sep = '|')\n",
    "\n",
    "#Replacing contractions compiled by Ahmed\n",
    "annotatedval['Sentence'] = [' '.join(contractions[p] if p in contractions else (contractions[p.lower()] if p.lower() in contractions else p) for p in y.split()) for y in annotatedval['Sentence']]\n",
    "\n",
    "#social_terms_organic_relevant_terms dictionary compiled by Ahmed\n",
    "annotatedval['Sentence'] = [' '.join(social_terms_organic_relevant_terms[p.lower()] if p.lower() in social_terms_organic_relevant_terms else p for p in y.split()) for y in annotatedval['Sentence']]\n",
    "\n",
    "#Replacement dictionary compiled by Ahmed\n",
    "annotatedval['Sentence'] = [re.sub('\\  +', ' ', ' '.join(replacement_dict[p] if p in replacement_dict else p for p in y.split())) for y in annotatedval['Sentence']]\n",
    "\n",
    "annotatedval.to_csv('C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.2/validation/new/dataframe.csv', header=True, index=False, sep='|', mode='w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic full exported train... Shape:  (3595, 2)\n",
      "Organic full exported val ... Shape:  (317, 2)\n"
     ]
    }
   ],
   "source": [
    "#Train & validation data for organic\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#train\n",
    "fine_tune_folder = 'C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.3/train/'\n",
    "fine_tune_file = fine_tune_folder + \"dataframe.csv\"\n",
    "annotatedtrain = pd.read_csv(fine_tune_file, sep = '|')\n",
    "\n",
    "#Organic full\n",
    "file_output = fine_tune_folder + \"output/cleansed_fine_tune_organic_full_train.csv\"\n",
    "fine_tune_organic_full = annotatedtrain[annotatedtrain.Entity.isin (['g','p', 'f', 'c']) & annotatedtrain.Sentiment.isin(['p','n', '0'])][['Sentence','Sentiment']].drop_duplicates()\n",
    "fine_tune_organic_full.to_csv(file_output, header=True, index=False, sep='|', mode='w+')\n",
    "file_output_pkl = fine_tune_folder + \"output/cleansed_fine_tune_organic_full_train.pkl\"\n",
    "fine_tune_organic_full.to_pickle(file_output_pkl)\n",
    "print('Organic full exported train... Shape: ', fine_tune_organic_full.shape)\n",
    "\n",
    "#validation\n",
    "\n",
    "fine_tune_folder_val = 'C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.3/validation/'\n",
    "fine_tune_file_val = fine_tune_folder_val + \"dataframe.csv\"\n",
    "annotatedval = pd.read_csv(fine_tune_file_val, sep = '|')\n",
    "\n",
    "#Organic full\n",
    "file_output_val = fine_tune_folder_val + \"output/cleansed_fine_tune_organic_full_validation.csv\"\n",
    "fine_tune_organic_full_val = annotatedval[annotatedval.Entity.isin (['g','p', 'f', 'c']) & annotatedval.Sentiment.isin(['p','n', '0'])][['Sentence','Sentiment']].drop_duplicates()\n",
    "fine_tune_organic_full_val.to_csv(file_output_val, header=True, index=False, sep='|', mode='w+')\n",
    "file_output_val_pkl = fine_tune_folder_val + \"output/cleansed_fine_tune_organic_full_validation.pkl\"\n",
    "fine_tune_organic_full_val.to_pickle(file_output_val_pkl)\n",
    "print('Organic full exported val ... Shape: ', fine_tune_organic_full_val.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic products exported test ... Shape:  (181, 2)\n"
     ]
    }
   ],
   "source": [
    "#test data for organic products only\n",
    "import pandas as pd\n",
    "\n",
    "fine_tune_folder_test = 'C:/Users/a_shy/Desktop/TUM/Sem 4/Application Project/data/organic_dataset/annotated_opinions/annotated_3rd_round/processed/train_test_validation V0.3/test/'\n",
    "fine_tune_file_test = fine_tune_folder_test + \"dataframe.csv\"\n",
    "annotatedtest = pd.read_csv(fine_tune_file_test, sep = '|')\n",
    "\n",
    "#Organic full\n",
    "file_output_test = fine_tune_folder_test + \"output/cleansed_fine_tune_organic_products_test.csv\"\n",
    "fine_tune_organic_full_test = annotatedtest[annotatedtest.Entity.isin (['p']) & annotatedtest.Sentiment.isin(['p','n', '0'])][['Sentence','Sentiment']].drop_duplicates()\n",
    "fine_tune_organic_full_test.to_csv(file_output_test, header=True, index=False, sep='|', mode='w+')\n",
    "file_output_test_pkl = fine_tune_folder_test + \"output/cleansed_fine_tune_organic_products_test.pkl\"\n",
    "fine_tune_organic_full_test.to_pickle(file_output_test_pkl)\n",
    "print('Organic products exported test ... Shape: ', fine_tune_organic_full_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
