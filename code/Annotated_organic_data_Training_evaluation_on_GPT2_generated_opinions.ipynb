{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOTzp8O36CyQ"
   },
   "source": [
    "# Getting Started\n",
    "\n",
    "This section sets up the environment for access to the Universal Sentence Encoder on TF Hub and provides examples of applying the encoder to words, sentences, and paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "lVjNK8shFKOC",
    "outputId": "1e1b6e2e-0773-480b-ae20-dab2a81d015a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.3.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.0.3)\n",
      "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.16.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.5.3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=1.4.3->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (41.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Install the latest Tensorflow version.\n",
    "!pip3 install --quiet \"tensorflow>=1.7\"\n",
    "# Install TF-Hub.\n",
    "!pip3 install --quiet tensorflow-hub\n",
    "!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63Pd3nJnTl-i"
   },
   "source": [
    "More detailed information about installing Tensorflow can be found at [https://www.tensorflow.org/install/](https://www.tensorflow.org/install/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5bXdreR3-8fY",
    "outputId": "e11030f2-bcf1-4798-ff54-b78b8a875a9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSeY-MUQo2Ha"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zwty8Z6mAkdV"
   },
   "outputs": [],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/2\", \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"]\n",
    "embed = hub.Module(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "O2cYc2WEkSGP",
    "outputId": "3afb1b8d-d537-4a34-8cd7-a244faa1c707"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_size = embed.get_output_info_dict()['default'].get_shape()[1].value\n",
    "embed_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTvxsefv_lcJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_pickle(\"./drive/My Drive/cleansed_organic/cleansed_fine_tune_organic_full_train.pkl\")\n",
    "df_train.Sentiment = df_train.Sentiment.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "74_geFVHAJUf",
    "outputId": "575f65ff-de87-4ee5-a84e-263947a475d3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'Organic' agriculture goes along with that the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Organic farming is the only solution to get ri...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>So organic farming is the best alternative in ...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>But the argument is, it cannot satiate needs o...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Though the argument is valid,scientists proved...</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Sentence Sentiment\n",
       "6   'Organic' agriculture goes along with that the...         0\n",
       "48  Organic farming is the only solution to get ri...         p\n",
       "52  So organic farming is the best alternative in ...         p\n",
       "54  But the argument is, it cannot satiate needs o...         p\n",
       "55  Though the argument is valid,scientists proved...         p"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3HAtd4X5DayF",
    "outputId": "82195188-a456-4472-ffcb-6bdfda18d61b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_counts = len(df_train.Sentiment.cat.categories)\n",
    "category_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sf9A4Xl6J7c6"
   },
   "source": [
    "## Wrap embed module in a Lambda layer\n",
    "Explicitly cast the input as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PRD3fWgJjOrP"
   },
   "outputs": [],
   "source": [
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "t3fllZkVjXKV",
    "outputId": "3e1dc4f0-53fd-4581-e68b-806a7cd06c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 132,099\n",
      "Trainable params: 132,099\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_text = layers.Input(shape=(1,), dtype=tf.string)\n",
    "embedding = layers.Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text)\n",
    "dense = layers.Dense(256, activation='relu')(embedding)\n",
    "pred = layers.Dense(category_counts, activation='softmax')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Ube1DvYEJ3q"
   },
   "outputs": [],
   "source": [
    "train_text = df_train['Sentence'].tolist()\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "train_label = np.asarray(pd.get_dummies(df_train.Sentiment), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WX3s8yIVFWHI",
    "outputId": "a4d0dc76-6ec4-4e7d-c74f-a5acfc1a9e77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3595, 1)"
      ]
     },
     "execution_count": 44,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9PfsPdG8FZBI",
    "outputId": "ba3b663d-6299-4baa-e2e8-0cfff51e1672"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3595, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "gPYVmBr2Fbob",
    "outputId": "0ab32b00-7e70-40aa-b482-9170d6261f18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X9MJnOnKI6F0"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_pickle(\"./drive/My Drive/cleansed_organic/cleansed_fine_tune_organic_full_validation.pkl\")\n",
    "df_test.Sentiment = df_test.Sentiment.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QWAjtjdeI9P4"
   },
   "outputs": [],
   "source": [
    "test_text = df_test['Sentence'].tolist()\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "test_label = np.asarray(pd.get_dummies(df_test.Sentiment), dtype = np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "J7CtxLhTB_Ue",
    "outputId": "1538bb89-4fd6-4ac4-a476-80bab0cfaefe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MD8A2vfnCAqx",
    "outputId": "8b9aa7c3-392a-4c59-e118-05767f2f8539"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(317, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bqcRy_JWXe0u"
   },
   "source": [
    "## Train Keras model and save weights\n",
    "This only train and save our Keras layers not the embed module' weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "_stfC_7VFhS8",
    "outputId": "f4be87cb-5228-4f6a-dc30-d8feb911bd52"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0821 21:17:09.035500 139682656565120 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0821 21:17:09.086400 139682656565120 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3595 samples, validate on 317 samples\n",
      "Epoch 1/10\n",
      "3595/3595 [==============================] - 7s 2ms/step - loss: 0.9769 - acc: 0.5104 - val_loss: 0.9787 - val_acc: 0.5047\n",
      "Epoch 2/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8887 - acc: 0.5819 - val_loss: 0.9841 - val_acc: 0.5142\n",
      "Epoch 3/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8694 - acc: 0.5930 - val_loss: 0.9387 - val_acc: 0.5300\n",
      "Epoch 4/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8387 - acc: 0.6156 - val_loss: 0.9468 - val_acc: 0.5079\n",
      "Epoch 5/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8265 - acc: 0.6181 - val_loss: 0.9245 - val_acc: 0.5457\n",
      "Epoch 6/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8074 - acc: 0.6317 - val_loss: 0.9254 - val_acc: 0.5457\n",
      "Epoch 7/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.7904 - acc: 0.6473 - val_loss: 0.9197 - val_acc: 0.5552\n",
      "Epoch 8/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.7727 - acc: 0.6531 - val_loss: 0.9257 - val_acc: 0.5521\n",
      "Epoch 9/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.7591 - acc: 0.6670 - val_loss: 0.9531 - val_acc: 0.5457\n",
      "Epoch 10/10\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.7407 - acc: 0.6790 - val_loss: 0.9444 - val_acc: 0.5079\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=10,\n",
    "            batch_size=32)\n",
    "  model.save_weights('./drive/My Drive/cleansed_organic/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fu05f5fuZ5E4",
    "outputId": "7b2cf33c-6b56-46e4-ae9a-0e35a1f156bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3595 samples, validate on 317 samples\n",
      "Epoch 1/20\n",
      "3595/3595 [==============================] - 8s 2ms/step - loss: 0.9986 - acc: 0.5043 - val_loss: 0.9952 - val_acc: 0.4921\n",
      "Epoch 2/20\n",
      "3595/3595 [==============================] - 4s 985us/step - loss: 0.9010 - acc: 0.5783 - val_loss: 0.9617 - val_acc: 0.4984\n",
      "Epoch 3/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8743 - acc: 0.5942 - val_loss: 0.9384 - val_acc: 0.5426\n",
      "Epoch 4/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8521 - acc: 0.6128 - val_loss: 0.9314 - val_acc: 0.5394\n",
      "Epoch 5/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8397 - acc: 0.6159 - val_loss: 0.9262 - val_acc: 0.5426\n",
      "Epoch 6/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8287 - acc: 0.6209 - val_loss: 0.9476 - val_acc: 0.5331\n",
      "Epoch 7/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.8180 - acc: 0.6309 - val_loss: 0.9253 - val_acc: 0.5363\n",
      "Epoch 8/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.7996 - acc: 0.6417 - val_loss: 0.9294 - val_acc: 0.5331\n",
      "Epoch 9/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.7962 - acc: 0.6498 - val_loss: 0.9370 - val_acc: 0.5237\n",
      "Epoch 10/20\n",
      "3595/3595 [==============================] - 4s 994us/step - loss: 0.7787 - acc: 0.6576 - val_loss: 0.9221 - val_acc: 0.5426\n",
      "Epoch 11/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.7686 - acc: 0.6567 - val_loss: 0.9385 - val_acc: 0.5457\n",
      "Epoch 12/20\n",
      "3595/3595 [==============================] - 4s 995us/step - loss: 0.7624 - acc: 0.6673 - val_loss: 0.9266 - val_acc: 0.5426\n",
      "Epoch 13/20\n",
      "3595/3595 [==============================] - 4s 987us/step - loss: 0.7426 - acc: 0.6815 - val_loss: 0.9304 - val_acc: 0.5363\n",
      "Epoch 14/20\n",
      "3595/3595 [==============================] - 4s 1ms/step - loss: 0.7319 - acc: 0.6851 - val_loss: 0.9318 - val_acc: 0.5237\n",
      "Epoch 15/20\n",
      "3595/3595 [==============================] - 4s 985us/step - loss: 0.7173 - acc: 0.6954 - val_loss: 0.9357 - val_acc: 0.5237\n",
      "Epoch 16/20\n",
      "3595/3595 [==============================] - 4s 997us/step - loss: 0.7035 - acc: 0.6946 - val_loss: 0.9471 - val_acc: 0.5394\n",
      "Epoch 17/20\n",
      "3595/3595 [==============================] - 4s 996us/step - loss: 0.6993 - acc: 0.7024 - val_loss: 0.9563 - val_acc: 0.5331\n",
      "Epoch 18/20\n",
      "3595/3595 [==============================] - 4s 993us/step - loss: 0.6877 - acc: 0.7082 - val_loss: 0.9555 - val_acc: 0.5205\n",
      "Epoch 19/20\n",
      "3595/3595 [==============================] - 4s 989us/step - loss: 0.6695 - acc: 0.7216 - val_loss: 0.9698 - val_acc: 0.5174\n",
      "Epoch 20/20\n",
      "3595/3595 [==============================] - 4s 998us/step - loss: 0.6553 - acc: 0.7268 - val_loss: 0.9701 - val_acc: 0.5205\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=20,\n",
    "            batch_size=64)\n",
    "  model.save_weights('./drive/My Drive/cleansed_organic/model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nWgrW7I1bNdG",
    "outputId": "f925f6a2-fd4c-4711-f0a6-e172f6fe5b9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3595 samples, validate on 317 samples\n",
      "Epoch 1/20\n",
      "3595/3595 [==============================] - 9s 3ms/step - loss: 1.0214 - acc: 0.4904 - val_loss: 1.0122 - val_acc: 0.4890\n",
      "Epoch 2/20\n",
      "3595/3595 [==============================] - 3s 908us/step - loss: 0.9269 - acc: 0.5669 - val_loss: 0.9931 - val_acc: 0.4890\n",
      "Epoch 3/20\n",
      "3595/3595 [==============================] - 3s 952us/step - loss: 0.8941 - acc: 0.5736 - val_loss: 0.9528 - val_acc: 0.5300\n",
      "Epoch 4/20\n",
      "3595/3595 [==============================] - 3s 965us/step - loss: 0.8701 - acc: 0.5983 - val_loss: 0.9440 - val_acc: 0.5363\n",
      "Epoch 5/20\n",
      "3595/3595 [==============================] - 3s 946us/step - loss: 0.8625 - acc: 0.5986 - val_loss: 0.9422 - val_acc: 0.5394\n",
      "Epoch 6/20\n",
      "3595/3595 [==============================] - 3s 948us/step - loss: 0.8498 - acc: 0.6075 - val_loss: 0.9459 - val_acc: 0.5300\n",
      "Epoch 7/20\n",
      "3595/3595 [==============================] - 3s 959us/step - loss: 0.8493 - acc: 0.6120 - val_loss: 0.9330 - val_acc: 0.5268\n",
      "Epoch 8/20\n",
      "3595/3595 [==============================] - 3s 957us/step - loss: 0.8373 - acc: 0.6125 - val_loss: 0.9351 - val_acc: 0.5489\n",
      "Epoch 9/20\n",
      "3595/3595 [==============================] - 4s 976us/step - loss: 0.8224 - acc: 0.6256 - val_loss: 0.9332 - val_acc: 0.5457\n",
      "Epoch 10/20\n",
      "3595/3595 [==============================] - 3s 959us/step - loss: 0.8124 - acc: 0.6306 - val_loss: 0.9256 - val_acc: 0.5521\n",
      "Epoch 11/20\n",
      "3595/3595 [==============================] - 3s 942us/step - loss: 0.8038 - acc: 0.6331 - val_loss: 0.9282 - val_acc: 0.5457\n",
      "Epoch 12/20\n",
      "3595/3595 [==============================] - 3s 941us/step - loss: 0.8000 - acc: 0.6456 - val_loss: 0.9246 - val_acc: 0.5268\n",
      "Epoch 13/20\n",
      "3595/3595 [==============================] - 3s 926us/step - loss: 0.7858 - acc: 0.6526 - val_loss: 0.9210 - val_acc: 0.5457\n",
      "Epoch 14/20\n",
      "3595/3595 [==============================] - 3s 914us/step - loss: 0.7892 - acc: 0.6476 - val_loss: 0.9262 - val_acc: 0.5489\n",
      "Epoch 15/20\n",
      "3595/3595 [==============================] - 3s 930us/step - loss: 0.7732 - acc: 0.6615 - val_loss: 0.9433 - val_acc: 0.5521\n",
      "Epoch 16/20\n",
      "3595/3595 [==============================] - 3s 953us/step - loss: 0.7644 - acc: 0.6626 - val_loss: 0.9373 - val_acc: 0.5457\n",
      "Epoch 17/20\n",
      "3595/3595 [==============================] - 3s 948us/step - loss: 0.7581 - acc: 0.6701 - val_loss: 0.9349 - val_acc: 0.5426\n",
      "Epoch 18/20\n",
      "3595/3595 [==============================] - 3s 937us/step - loss: 0.7497 - acc: 0.6818 - val_loss: 0.9395 - val_acc: 0.5457\n",
      "Epoch 19/20\n",
      "3595/3595 [==============================] - 3s 955us/step - loss: 0.7404 - acc: 0.6868 - val_loss: 0.9365 - val_acc: 0.5426\n",
      "Epoch 20/20\n",
      "3595/3595 [==============================] - 3s 937us/step - loss: 0.7313 - acc: 0.6898 - val_loss: 0.9437 - val_acc: 0.5331\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=20,\n",
    "            batch_size=128)\n",
    "  model.save_weights('./drive/My Drive/cleansed_organic/model3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "eJjVdhyPbPGj",
    "outputId": "2c5a4afe-fd72-439f-be85-1485ba488c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3595 samples, validate on 317 samples\n",
      "Epoch 1/13\n",
      "3595/3595 [==============================] - 9s 3ms/step - loss: 1.0214 - acc: 0.4904 - val_loss: 1.0122 - val_acc: 0.4890\n",
      "Epoch 2/13\n",
      "3595/3595 [==============================] - 5s 2ms/step - loss: 0.9269 - acc: 0.5669 - val_loss: 0.9931 - val_acc: 0.4890\n",
      "Epoch 3/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8941 - acc: 0.5736 - val_loss: 0.9528 - val_acc: 0.5300\n",
      "Epoch 4/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8701 - acc: 0.5983 - val_loss: 0.9440 - val_acc: 0.5363\n",
      "Epoch 5/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8625 - acc: 0.5986 - val_loss: 0.9422 - val_acc: 0.5394\n",
      "Epoch 6/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8498 - acc: 0.6075 - val_loss: 0.9459 - val_acc: 0.5300\n",
      "Epoch 7/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8493 - acc: 0.6120 - val_loss: 0.9330 - val_acc: 0.5268\n",
      "Epoch 8/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8373 - acc: 0.6125 - val_loss: 0.9351 - val_acc: 0.5489\n",
      "Epoch 9/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8224 - acc: 0.6256 - val_loss: 0.9332 - val_acc: 0.5457\n",
      "Epoch 10/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8124 - acc: 0.6306 - val_loss: 0.9256 - val_acc: 0.5521\n",
      "Epoch 11/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8038 - acc: 0.6342 - val_loss: 0.9284 - val_acc: 0.5457\n",
      "Epoch 12/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.8000 - acc: 0.6451 - val_loss: 0.9244 - val_acc: 0.5268\n",
      "Epoch 13/13\n",
      "3595/3595 [==============================] - 6s 2ms/step - loss: 0.7858 - acc: 0.6545 - val_loss: 0.9211 - val_acc: 0.5363\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  history = model.fit(train_text, \n",
    "            train_label,\n",
    "            validation_data=(test_text, test_label),\n",
    "            epochs=13,\n",
    "            batch_size=128)\n",
    "  model.save_weights('./drive/My Drive/cleansed_organic/model4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nQux6qLdXabG"
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "CE9-PimeG1_o",
    "outputId": "6705d86c-66c7-4c7e-c428-68b2a5b37b0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fc4564af0b8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    }
   ],
   "source": [
    "new_text = []\n",
    "belief_pd = pd.read_excel('./drive/My Drive/cleansed_organic/Belief_statements_output.xlsx')\n",
    "belief_pd['Output_fine_tune_organic_products_positive_prediction'] = ''\n",
    "for index, row in belief_pd.iterrows():\n",
    "  new_text.append(row['Output_fine_tune_organic_products_positive']) \n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./drive/My Drive/cleansed_organic/model4.h5')  \n",
    "  predicts = model.predict(new_text, batch_size=32)\n",
    "  \n",
    "categories = df_train.Sentiment.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "for index, row in belief_pd.iterrows():\n",
    "#   print(index, predict_labels[index] )\n",
    "  belief_pd.at[index,'Output_fine_tune_organic_products_positive_prediction'] = predict_labels[index]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "UTr0dgBtIe6o",
    "outputId": "6e7e4180-2190-4dec-f413-d014faa1b726"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fc408925ba8>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    }
   ],
   "source": [
    "new_text = []\n",
    "# belief_pd = pd.read_excel('./drive/My Drive/cleansed_organic/Belief_statements_output.xlsx')\n",
    "belief_pd['Output_fine_tune_organic_products_negative_prediction'] = ''\n",
    "for index, row in belief_pd.iterrows():\n",
    "  new_text.append(row['Output_fine_tune_organic_products_negative']) \n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./drive/My Drive/cleansed_organic/model4.h5')  \n",
    "  predicts = model.predict(new_text, batch_size=32)\n",
    "  \n",
    "categories = df_train.Sentiment.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "for index, row in belief_pd.iterrows():\n",
    "#   print(index, predict_labels[index] )\n",
    "  belief_pd.at[index,'Output_fine_tune_organic_products_negative_prediction'] = predict_labels[index]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Qxlzd4zvMwcl",
    "outputId": "950608b0-2872-4cf1-ff46-f253664c0ef6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fc40893db38>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    }
   ],
   "source": [
    "new_text = []\n",
    "# belief_pd = pd.read_excel('./drive/My Drive/cleansed_organic/Belief_statements_output.xlsx')\n",
    "belief_pd['Output_fine_tune_organic_products_neutral_prediction'] = ''\n",
    "for index, row in belief_pd.iterrows():\n",
    "  new_text.append(row['Output_fine_tune_organic_products_neutral']) \n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./drive/My Drive/cleansed_organic/model4.h5')  \n",
    "  predicts = model.predict(new_text, batch_size=32)\n",
    "  \n",
    "categories = df_train.Sentiment.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "for index, row in belief_pd.iterrows():\n",
    "#   print(index, predict_labels[index] )\n",
    "  belief_pd.at[index,'Output_fine_tune_organic_products_neutral_prediction'] = predict_labels[index]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XI94Uv0TNKnd"
   },
   "outputs": [],
   "source": [
    "belief_pd.to_excel('./drive/My Drive/cleansed_organic/Belief_statements_output_final_new64_20.xlsx', index = None, header=True, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "wCLzy3WDxb8d",
    "outputId": "912dcf70-1d8e-44f0-9ea0-66de6baf7f18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fc406a93518>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n",
      "Exception ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7fc406a93358>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\", line 1473, in __del__\n",
      "    self._session._session, self._handle)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: (None, None, 'Session has been closed.')\n"
     ]
    }
   ],
   "source": [
    "new_text = []\n",
    "belief_pd = pd.read_excel('./drive/My Drive/cleansed_organic/Belief_statements_output.xlsx')\n",
    "belief_pd['Output_fine_tune_organic_products_full_positive_prediction'] = ''\n",
    "for index, row in belief_pd.iterrows():\n",
    "  new_text.append(row['Output_fine_tune_organic_full_positive']) \n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./drive/My Drive/cleansed_organic/model4.h5')  \n",
    "  predicts = model.predict(new_text, batch_size=32)\n",
    "  \n",
    "categories = df_train.Sentiment.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "for index, row in belief_pd.iterrows():\n",
    "#   print(index, predict_labels[index] )\n",
    "  belief_pd.at[index,'Output_fine_tune_organic_full_positive_prediction'] = predict_labels[index]\n",
    "  \n",
    "new_text = []\n",
    "# belief_pd = pd.read_excel('./drive/My Drive/cleansed_organic/Belief_statements_output.xlsx')\n",
    "belief_pd['Output_fine_tune_organic_full_negative_prediction'] = ''\n",
    "for index, row in belief_pd.iterrows():\n",
    "  new_text.append(row['Output_fine_tune_organic_full_negative']) \n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./drive/My Drive/cleansed_organic/model4.h5')  \n",
    "  predicts = model.predict(new_text, batch_size=32)\n",
    "  \n",
    "categories = df_train.Sentiment.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "for index, row in belief_pd.iterrows():\n",
    "#   print(index, predict_labels[index] )\n",
    "  belief_pd.at[index,'Output_fine_tune_organic_full_negative_prediction'] = predict_labels[index]\n",
    "    \n",
    "new_text = []\n",
    "# belief_pd = pd.read_excel('./drive/My Drive/cleansed_organic/Belief_statements_output.xlsx')\n",
    "belief_pd['Output_fine_tune_organic_full_neutral_prediction'] = ''\n",
    "for index, row in belief_pd.iterrows():\n",
    "  new_text.append(row['Output_fine_tune_organic_full_neutral']) \n",
    "\n",
    "new_text = np.array(new_text, dtype=object)[:, np.newaxis]\n",
    "with tf.Session() as session:\n",
    "  K.set_session(session)\n",
    "  session.run(tf.global_variables_initializer())\n",
    "  session.run(tf.tables_initializer())\n",
    "  model.load_weights('./drive/My Drive/cleansed_organic/model4.h5')  \n",
    "  predicts = model.predict(new_text, batch_size=32)\n",
    "  \n",
    "categories = df_train.Sentiment.cat.categories.tolist()\n",
    "predict_logits = predicts.argmax(axis=1)\n",
    "predict_labels = [categories[logit] for logit in predict_logits]\n",
    "for index, row in belief_pd.iterrows():\n",
    "#   print(index, predict_labels[index] )\n",
    "  belief_pd.at[index,'Output_fine_tune_organic_full_neutral_prediction'] = predict_labels[index]\n",
    "      \n",
    "belief_pd.to_excel('./drive/My Drive/cleansed_organic/Belief_statements_output_full_final_new128_13.xlsx', index = None, header=True, encoding='utf-8-sig')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hYhmukbSKpnp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Transfer Learning - Semantic Similarity with TF-Hub Universal Encoder",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
